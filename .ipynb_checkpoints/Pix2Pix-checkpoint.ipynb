{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, pickle\n",
    "from lib import networks, utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input channel for generator\n",
    "in_ngc=3\n",
    "#output channel for generator\n",
    "out_ngc=3\n",
    "#input channel for discriminator\n",
    "in_ndc=6\n",
    "#output channel for discriminator\n",
    "out_ndc=1\n",
    "\n",
    "batch_size=2\n",
    "#number of filters in the first layer of generator\n",
    "ngf=64\n",
    "#number of filters in the first layer of discriminator\n",
    "ndf=32\n",
    "#the number of resnet block layer for generator\n",
    "nb=9\n",
    "#input size\n",
    "input_size=128\n",
    "train_epoch=100\n",
    "\n",
    "#Discriminator learning rate, default=0.0002\n",
    "lrD=0.0002\n",
    "#Generator learning rate, default=0.0002\n",
    "lrG=0.0002\n",
    "#lambda for content loss\n",
    "con_lambda=10\n",
    "#beta1 for Adam optimizer\n",
    "beta1=0.5\n",
    "#beta2 for Adam optimizer\n",
    "beta2=0.999\n",
    "\n",
    "n_downsampling = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'pix2pix_eyes_1'\n",
    "result_path = project_name+'_results'\n",
    "data_name = 'data/combine'\n",
    "\n",
    "# results save path\n",
    "if not os.path.isdir(result_path):\n",
    "    os.makedirs(result_path)\n",
    "#ensure data folder exists\n",
    "if not os.path.isdir(data_name):\n",
    "    os.makedirs(data_name)\n",
    "    print(\"data folder does not exist!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((input_size, 2*input_size)),\n",
    "        transforms.ColorJitter(0.1,0.1,0.1,0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# train_loader = utils.data_load(data_name, 'train', train_transform, batch_size, shuffle=False, drop_last=True)\n",
    "# test_loader = utils.data_load(data_name, 'test', train_transform, batch_size, shuffle=False, drop_last=True)\n",
    "train_loader = torch.utils.data.DataLoader(datasets.ImageFolder(data_name, train_transform), batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n",
    "\n",
    "# G = networks.generator(in_ngc, out_ngc, ngf, nb)\n",
    "G = networks.UnetGenerator(in_ngc, out_ngc, 7, ngf)\n",
    "D = networks.discriminator(in_ndc, out_ndc, ndf)\n",
    "# D = networks.wgan_discriminator(in_ndc, ndf, input_size, n_downsampling)\n",
    "\n",
    "G.to(device)\n",
    "D.to(device)\n",
    "G.train()\n",
    "D.train();\n",
    "# print('---------- Networks initialized -------------')\n",
    "# utils.print_network(G)\n",
    "# utils.print_network(D)\n",
    "# print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "# GAN_loss = nn.BCELoss().to(device)\n",
    "GAN_loss = nn.MSELoss().to(device)\n",
    "L1_loss = nn.L1Loss().to(device)\n",
    "# def D_loss_criterion(D_decision):\n",
    "#     return D_decision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=lrG, betas=(beta1, beta2))\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=lrD, betas=(beta1, beta2))\n",
    "G_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=G_optimizer, milestones=[train_epoch // 2, train_epoch // 4 * 3], gamma=0.1)\n",
    "D_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=D_optimizer, milestones=[train_epoch // 2, train_epoch // 4 * 3], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = {}\n",
    "train_hist['Disc_loss'] = []\n",
    "train_hist['Gen_loss'] = []\n",
    "train_hist['Con_loss'] = []\n",
    "train_hist['per_epoch_time'] = []\n",
    "train_hist['Gen_loss_one_epoch']=[]\n",
    "train_hist['Disc_loss_one_epoch']=[]\n",
    "train_hist['Con_loss_one_epoch']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting_epoch is used to avoid overriding of the previously generated results\n",
    "starting_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start!\n",
      "[1/100] - time: 1.84, Disc loss: 0.157, Gen loss: 0.338, Con loss: 4.791\n",
      "[2/100] - time: 1.82, Disc loss: 0.086, Gen loss: 0.468, Con loss: 4.522\n",
      "[3/100] - time: 1.83, Disc loss: 0.071, Gen loss: 0.525, Con loss: 4.443\n",
      "[4/100] - time: 1.82, Disc loss: 0.058, Gen loss: 0.559, Con loss: 4.430\n",
      "[5/100] - time: 1.82, Disc loss: 0.075, Gen loss: 0.520, Con loss: 4.454\n",
      "[6/100] - time: 1.82, Disc loss: 0.084, Gen loss: 0.540, Con loss: 4.551\n",
      "[7/100] - time: 1.83, Disc loss: 0.098, Gen loss: 0.493, Con loss: 4.589\n",
      "[8/100] - time: 1.82, Disc loss: 0.092, Gen loss: 0.565, Con loss: 4.478\n",
      "[9/100] - time: 1.83, Disc loss: 0.092, Gen loss: 0.543, Con loss: 4.572\n",
      "[10/100] - time: 1.82, Disc loss: 0.109, Gen loss: 0.513, Con loss: 4.583\n",
      "[11/100] - time: 1.83, Disc loss: 0.101, Gen loss: 0.505, Con loss: 4.557\n",
      "[12/100] - time: 1.82, Disc loss: 0.116, Gen loss: 0.513, Con loss: 4.370\n",
      "[13/100] - time: 1.83, Disc loss: 0.097, Gen loss: 0.534, Con loss: 4.405\n",
      "[14/100] - time: 1.82, Disc loss: 0.104, Gen loss: 0.527, Con loss: 4.344\n",
      "[15/100] - time: 1.83, Disc loss: 0.120, Gen loss: 0.487, Con loss: 4.327\n",
      "[16/100] - time: 1.82, Disc loss: 0.130, Gen loss: 0.492, Con loss: 4.355\n",
      "[17/100] - time: 1.82, Disc loss: 0.124, Gen loss: 0.503, Con loss: 4.237\n",
      "[18/100] - time: 1.83, Disc loss: 0.128, Gen loss: 0.478, Con loss: 4.229\n",
      "[19/100] - time: 1.84, Disc loss: 0.112, Gen loss: 0.512, Con loss: 4.076\n",
      "[20/100] - time: 1.84, Disc loss: 0.126, Gen loss: 0.416, Con loss: 4.059\n",
      "[21/100] - time: 1.82, Disc loss: 0.130, Gen loss: 0.469, Con loss: 4.118\n",
      "[22/100] - time: 1.82, Disc loss: 0.141, Gen loss: 0.449, Con loss: 3.995\n",
      "[23/100] - time: 1.82, Disc loss: 0.120, Gen loss: 0.489, Con loss: 3.966\n",
      "[24/100] - time: 1.82, Disc loss: 0.123, Gen loss: 0.477, Con loss: 3.753\n",
      "[25/100] - time: 1.82, Disc loss: 0.143, Gen loss: 0.463, Con loss: 3.655\n",
      "[26/100] - time: 1.82, Disc loss: 0.121, Gen loss: 0.450, Con loss: 3.736\n",
      "[27/100] - time: 1.84, Disc loss: 0.139, Gen loss: 0.445, Con loss: 3.596\n",
      "[28/100] - time: 1.82, Disc loss: 0.125, Gen loss: 0.438, Con loss: 3.576\n",
      "[29/100] - time: 1.83, Disc loss: 0.137, Gen loss: 0.445, Con loss: 3.464\n",
      "[30/100] - time: 1.82, Disc loss: 0.142, Gen loss: 0.420, Con loss: 3.393\n",
      "[31/100] - time: 1.82, Disc loss: 0.142, Gen loss: 0.415, Con loss: 3.396\n",
      "[32/100] - time: 1.82, Disc loss: 0.127, Gen loss: 0.451, Con loss: 3.245\n",
      "[33/100] - time: 1.83, Disc loss: 0.152, Gen loss: 0.383, Con loss: 3.166\n",
      "[34/100] - time: 1.83, Disc loss: 0.128, Gen loss: 0.412, Con loss: 3.219\n",
      "[35/100] - time: 1.83, Disc loss: 0.140, Gen loss: 0.444, Con loss: 3.198\n",
      "[36/100] - time: 1.82, Disc loss: 0.127, Gen loss: 0.445, Con loss: 3.060\n",
      "[37/100] - time: 1.83, Disc loss: 0.142, Gen loss: 0.458, Con loss: 3.102\n",
      "[38/100] - time: 1.82, Disc loss: 0.141, Gen loss: 0.429, Con loss: 3.006\n",
      "[39/100] - time: 1.82, Disc loss: 0.128, Gen loss: 0.435, Con loss: 3.060\n",
      "[40/100] - time: 1.82, Disc loss: 0.141, Gen loss: 0.456, Con loss: 2.898\n",
      "[41/100] - time: 1.84, Disc loss: 0.142, Gen loss: 0.418, Con loss: 2.880\n",
      "[42/100] - time: 1.82, Disc loss: 0.140, Gen loss: 0.439, Con loss: 2.926\n",
      "[43/100] - time: 1.83, Disc loss: 0.133, Gen loss: 0.422, Con loss: 2.850\n",
      "[44/100] - time: 1.82, Disc loss: 0.130, Gen loss: 0.450, Con loss: 2.833\n",
      "[45/100] - time: 1.82, Disc loss: 0.128, Gen loss: 0.434, Con loss: 2.961\n",
      "[46/100] - time: 1.82, Disc loss: 0.144, Gen loss: 0.450, Con loss: 2.770\n",
      "[47/100] - time: 1.82, Disc loss: 0.132, Gen loss: 0.428, Con loss: 2.695\n",
      "[48/100] - time: 1.83, Disc loss: 0.140, Gen loss: 0.434, Con loss: 2.775\n",
      "[49/100] - time: 1.82, Disc loss: 0.143, Gen loss: 0.462, Con loss: 2.742\n",
      "[50/100] - time: 1.82, Disc loss: 0.132, Gen loss: 0.457, Con loss: 2.719\n",
      "[51/100] - time: 1.82, Disc loss: 0.107, Gen loss: 0.432, Con loss: 2.599\n",
      "[52/100] - time: 1.82, Disc loss: 0.110, Gen loss: 0.454, Con loss: 2.460\n",
      "[53/100] - time: 1.82, Disc loss: 0.104, Gen loss: 0.467, Con loss: 2.451\n",
      "[54/100] - time: 1.82, Disc loss: 0.108, Gen loss: 0.444, Con loss: 2.453\n",
      "[55/100] - time: 1.83, Disc loss: 0.105, Gen loss: 0.453, Con loss: 2.439\n",
      "[56/100] - time: 1.82, Disc loss: 0.103, Gen loss: 0.471, Con loss: 2.449\n",
      "[57/100] - time: 1.82, Disc loss: 0.097, Gen loss: 0.458, Con loss: 2.430\n",
      "[58/100] - time: 1.83, Disc loss: 0.101, Gen loss: 0.479, Con loss: 2.404\n",
      "[59/100] - time: 1.83, Disc loss: 0.094, Gen loss: 0.487, Con loss: 2.401\n",
      "[60/100] - time: 1.82, Disc loss: 0.098, Gen loss: 0.477, Con loss: 2.433\n",
      "[61/100] - time: 1.82, Disc loss: 0.094, Gen loss: 0.481, Con loss: 2.452\n",
      "[62/100] - time: 1.83, Disc loss: 0.104, Gen loss: 0.487, Con loss: 2.490\n",
      "[63/100] - time: 1.85, Disc loss: 0.097, Gen loss: 0.478, Con loss: 2.432\n",
      "[64/100] - time: 1.84, Disc loss: 0.102, Gen loss: 0.471, Con loss: 2.331\n",
      "[65/100] - time: 1.83, Disc loss: 0.092, Gen loss: 0.477, Con loss: 2.327\n",
      "[66/100] - time: 1.83, Disc loss: 0.100, Gen loss: 0.488, Con loss: 2.420\n",
      "[67/100] - time: 1.82, Disc loss: 0.108, Gen loss: 0.468, Con loss: 2.409\n",
      "[68/100] - time: 1.82, Disc loss: 0.100, Gen loss: 0.492, Con loss: 2.311\n",
      "[69/100] - time: 1.83, Disc loss: 0.094, Gen loss: 0.488, Con loss: 2.443\n",
      "[70/100] - time: 1.82, Disc loss: 0.100, Gen loss: 0.488, Con loss: 2.376\n",
      "[71/100] - time: 1.82, Disc loss: 0.104, Gen loss: 0.484, Con loss: 2.429\n",
      "[72/100] - time: 1.82, Disc loss: 0.088, Gen loss: 0.467, Con loss: 2.347\n",
      "[73/100] - time: 1.82, Disc loss: 0.100, Gen loss: 0.517, Con loss: 2.380\n",
      "[74/100] - time: 1.82, Disc loss: 0.095, Gen loss: 0.477, Con loss: 2.403\n",
      "[75/100] - time: 1.82, Disc loss: 0.097, Gen loss: 0.521, Con loss: 2.421\n",
      "[76/100] - time: 1.83, Disc loss: 0.094, Gen loss: 0.498, Con loss: 2.359\n",
      "[77/100] - time: 1.82, Disc loss: 0.093, Gen loss: 0.485, Con loss: 2.350\n",
      "[78/100] - time: 1.82, Disc loss: 0.086, Gen loss: 0.518, Con loss: 2.401\n",
      "[79/100] - time: 1.83, Disc loss: 0.099, Gen loss: 0.493, Con loss: 2.282\n",
      "[80/100] - time: 1.82, Disc loss: 0.083, Gen loss: 0.527, Con loss: 2.326\n",
      "[81/100] - time: 1.82, Disc loss: 0.100, Gen loss: 0.484, Con loss: 2.316\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3afbe553c7e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mtrain_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Con_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCon_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mGen_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mG_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('training start!')\n",
    "start_time = time.time()\n",
    "num_pool = 50\n",
    "fake_pool = utils.ImagePool(num_pool)\n",
    "# real = torch.ones(batch_size, 1, input_size // 4, input_size // 4).to(device)\n",
    "# fake = torch.zeros(batch_size, 1, input_size // 4, input_size // 4).to(device)\n",
    "for epoch in range(train_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    G.train()\n",
    "    G_scheduler.step()\n",
    "    D_scheduler.step()\n",
    "    Disc_losses = []\n",
    "    Gen_losses = []\n",
    "    Con_losses = []\n",
    "    for d, _ in train_loader:\n",
    "        # x is the image at left, the source image\n",
    "        # y is the image at right, the target image\n",
    "        x = d[:, :, :, :input_size]\n",
    "        y = d[:, :, :, input_size:]\n",
    "        x, y, d = x.to(device), y.to(device), d.to(device)\n",
    "        \n",
    "        # train D\n",
    "        for param in D.parameters():\n",
    "            param.requires_grad = True\n",
    "#             param.data.clamp_(-0.005,0.005)\n",
    "        D_optimizer.zero_grad()\n",
    "\n",
    "        real = torch.cat((y,x),1)\n",
    "        D_real = D(real)\n",
    "#         D_real_loss = D_loss_criterion(D_real)\n",
    "        D_real_loss = GAN_loss(D_real, 1-torch.rand(D_real.size(),device = device)/10.0)\n",
    "#         D_real_loss = GAN_loss(D_real, torch.ones(D_real.size(),device = device))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            G_ = G(x)\n",
    "        generated = torch.cat((G_,x), 1)\n",
    "        generated = fake_pool.query(generated.detach())\n",
    "        D_fake = D(generated)\n",
    "#         D_fake_loss = D_loss_criterion(D_fake)\n",
    "        D_fake_loss = GAN_loss(D_fake, torch.rand(D_fake.size(),device = device)/10.0)\n",
    "#         D_fake_loss = GAN_loss(D_fake, torch.zeros(D_fake.size(),device = device))\n",
    "\n",
    "        Disc_loss = 0.5 * (D_real_loss + D_fake_loss)\n",
    "#         Disc_loss = D_fake_loss - D_real_loss\n",
    "        Disc_losses.append(Disc_loss.item())\n",
    "        train_hist['Disc_loss'].append(Disc_loss.item())\n",
    "        Disc_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        # train G\n",
    "        for param in D.parameters():\n",
    "            param.requires_grad = False\n",
    "        G_optimizer.zero_grad()\n",
    "\n",
    "        G_ = G(x)\n",
    "        generated = torch.cat((G_,x), 1)\n",
    "        D_fake = D(generated)\n",
    "#         D_fake_loss = D_loss_criterion(D_fake)\n",
    "        D_fake_loss = GAN_loss(D_fake, torch.ones(D_fake.size(),device = device))\n",
    "\n",
    "        Con_loss = con_lambda * L1_loss(G_, y)\n",
    "\n",
    "        Gen_loss = D_fake_loss + Con_loss\n",
    "#         Gen_loss = -D_fake_loss + Con_loss\n",
    "\n",
    "        Gen_losses.append(D_fake_loss.item())\n",
    "        train_hist['Gen_loss'].append(D_fake_loss.item())\n",
    "        Con_losses.append(Con_loss.item())\n",
    "        train_hist['Con_loss'].append(Con_loss.item())\n",
    "\n",
    "        Gen_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "\n",
    "    per_epoch_time = time.time() - epoch_start_time\n",
    "    train_hist['per_epoch_time'].append(per_epoch_time)\n",
    "    \n",
    "    Gen_loss_avg = torch.mean(torch.FloatTensor(Gen_losses))\n",
    "    Con_loss_avg = torch.mean(torch.FloatTensor(Con_losses))\n",
    "    Disc_loss_avg =  torch.mean(torch.FloatTensor(Disc_losses))\n",
    "    \n",
    "    train_hist['Gen_loss_one_epoch'].append(Gen_loss_avg)\n",
    "    train_hist['Disc_loss_one_epoch'].append(Disc_loss_avg)\n",
    "    train_hist['Con_loss_one_epoch'].append(Con_loss_avg)\n",
    "    \n",
    "    print(\n",
    "    '[%d/%d] - time: %.2f, Disc loss: %.3f, Gen loss: %.3f, Con loss: %.3f' % ((starting_epoch + epoch + 1), train_epoch, per_epoch_time, Disc_loss_avg, Gen_loss_avg, Con_loss_avg))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        G.eval()\n",
    "        for n, (d, _) in enumerate(train_loader):\n",
    "            x = d[:, :, :, :input_size]\n",
    "            y = d[:, :, :, input_size:]            \n",
    "            x,y = x.to(device),y.to(device)\n",
    "            G_recon = G(x)\n",
    "            result = torch.cat((x[0], G_recon[0],y[0]), 2)\n",
    "            path = os.path.join(result_path, str(starting_epoch+epoch+1) + '_epoch_' + project_name + '_train_' + str(n + 1) + '.png')\n",
    "            plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
    "            if n == 2:\n",
    "                break\n",
    "#         for n, (d, _) in enumerate(test_loader):\n",
    "#             y = d[:, :, :, :input_size]\n",
    "#             x = d[:, :, :, input_size:]            \n",
    "#             x,y = x.to(device),y.to(device)\n",
    "#             G_recon = G(x)\n",
    "#             result = torch.cat((x[0], G_recon[0],y[0]), 2)\n",
    "#             path = os.path.join(result_path, str(starting_epoch+epoch+1) + '_epoch_' + project_name + '_test_' + str(n + 1) + '.png')\n",
    "#             plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
    "#             if n == 1:\n",
    "#                 break\n",
    "                \n",
    "        torch.save(G.state_dict(), os.path.join(result_path, 'generator_latest.pkl'))\n",
    "        torch.save(D.state_dict(), os.path.join(result_path, 'discriminator_latest.pkl'))\n",
    "        with open(os.path.join(result_path,  'train_hist.pkl'), 'wb') as f:\n",
    "            pickle.dump(train_hist, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((input_size, 2*input_size)),\n",
    "        transforms.ColorJitter(0.1,0.1,0.1,0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(datasets.ImageFolder('data/eye_test', train_transform), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_result_path = 'pix2pix_eyes_test_results'\n",
    "\n",
    "# results save path\n",
    "if not os.path.isdir(test_result_path):\n",
    "    os.makedirs(test_result_path)\n",
    "\n",
    "with torch.no_grad():\n",
    "    G.eval()\n",
    "    for n, (d, _) in enumerate(test_loader):\n",
    "#         x = d[:, :, :, :input_size]\n",
    "#         y = d[:, :, :, input_size:]            \n",
    "#         x = x.to(device)\n",
    "#         y = y.to(device)\n",
    "        d = d.to(device)\n",
    "        G_recon = G(d)\n",
    "        result = torch.cat((d[0], G_recon[0]), 2)\n",
    "        path = os.path.join(test_result_path, str(starting_epoch+epoch+1) + '_epoch_' + project_name + '_test_' + str(n + 1) + '.png')\n",
    "        plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
