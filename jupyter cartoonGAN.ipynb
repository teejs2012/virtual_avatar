{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, pickle, argparse, networks, utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from edge_promoting import edge_promoting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='project_name'\n",
    "#source data path\n",
    "src_data='src_data_path'\n",
    "#target data path\n",
    "tgt_data='tgt_data_path'\n",
    "#pre-trained VGG19 model path\n",
    "vgg_model='pre_trained_VGG19_model_path/vgg19.pth'\n",
    "#input channel for generator\n",
    "in_ngc=3\n",
    "#output channel for generator\n",
    "out_ngc=3\n",
    "#input channel for discriminator\n",
    "in_ndc=3\n",
    "#output channel for discriminator\n",
    "out_ndc=1\n",
    "batch_size=8\n",
    "ngf=64\n",
    "ndf=32\n",
    "#the number of resnet block layer for generator\n",
    "nb=8\n",
    "#input size\n",
    "input_size=256\n",
    "train_epoch=50\n",
    "pre_train_epoch=10\n",
    "#Discriminator learning rate, default=0.0002\n",
    "lrD=0.0002\n",
    "#Generator learning rate, default=0.0002\n",
    "lrG=0.0002\n",
    "#lambda for content loss\n",
    "con_lambda=10\n",
    "#beta1 for Adam optimizer\n",
    "beta1=0.5\n",
    "#beta2 for Adam optimizer\n",
    "beta2=0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results save path\n",
    "if not os.path.isdir(os.path.join(name + '_results', 'Reconstruction')):\n",
    "    os.makedirs(os.path.join(name + '_results', 'Reconstruction'))\n",
    "if not os.path.isdir(os.path.join(name + '_results', 'Transfer')):\n",
    "    os.makedirs(os.path.join(name + '_results', 'Transfer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup source and target folder\n",
    "if not os.path.isdir(os.path.join('data',tgt_data,'train')):\n",
    "    os.makedirs(os.path.join('data',tgt_data,'train'))\n",
    "if not os.path.isdir(os.path.join('data',src_data,'train')):\n",
    "    os.makedirs(os.path.join('data',src_data,'train'))\n",
    "if not os.path.isdir(os.path.join('data',src_data,'test')):\n",
    "    os.makedirs(os.path.join('data',src_data,'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge-promoting already done\n"
     ]
    }
   ],
   "source": [
    "# edge-promoting\n",
    "if not os.path.isdir(os.path.join('data', tgt_data, 'pair')):\n",
    "    print('edge-promoting start!!')\n",
    "    edge_promoting(os.path.join('data', tgt_data, 'train'), os.path.join('data', tgt_data, 'pair'))\n",
    "else:\n",
    "    print('edge-promoting already done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader\n",
    "src_transform = transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "tgt_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "train_loader_src = utils.data_load(os.path.join('data', src_data), 'train', src_transform, batch_size, shuffle=True, drop_last=True)\n",
    "train_loader_tgt = utils.data_load(os.path.join('data', tgt_data), 'pair', tgt_transform, batch_size, shuffle=True, drop_last=True)\n",
    "test_loader_src = utils.data_load(os.path.join('data', src_data), 'test', src_transform, 1, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks initialized -------------\n",
      "generator(\n",
      "  (down_convs): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (10): ReLU(inplace)\n",
      "  )\n",
      "  (resnet_blocks): Sequential(\n",
      "    (0): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (1): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (2): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (3): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (4): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (5): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (6): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (7): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "  )\n",
      "  (up_convs): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace)\n",
      "    (4): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "    (9): Tanh()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 11406915\n",
      "discriminator(\n",
      "  (convs): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (11): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (14): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (15): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 1128385\n",
      "VGG19(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 143667240\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# network\n",
    "G = networks.generator(in_ngc, out_ngc, ngf, nb)\n",
    "D = networks.discriminator(in_ndc, out_ndc, ndf)\n",
    "VGG = networks.VGG19(init_weights=vgg_model, feature_mode=True)\n",
    "G.to(device)\n",
    "D.to(device)\n",
    "VGG.to(device)\n",
    "G.train()\n",
    "D.train()\n",
    "VGG.eval()\n",
    "print('---------- Networks initialized -------------')\n",
    "utils.print_network(G)\n",
    "utils.print_network(D)\n",
    "utils.print_network(VGG)\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "BCE_loss = nn.BCELoss().to(device)\n",
    "L1_loss = nn.L1Loss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=lrG, betas=(beta1, beta2))\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=lrD, betas=(beta1, beta2))\n",
    "G_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=G_optimizer, milestones=[train_epoch // 2, train_epoch // 4 * 3], gamma=0.1)\n",
    "D_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=D_optimizer, milestones=[train_epoch // 2, train_epoch // 4 * 3], gamma=0.1)\n",
    "\n",
    "pre_train_hist = {}\n",
    "pre_train_hist['Recon_loss'] = []\n",
    "pre_train_hist['per_epoch_time'] = []\n",
    "pre_train_hist['total_time'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training start!\n",
      "[1/10] - time: 6.81, Recon loss: 24.140\n",
      "[2/10] - time: 0.22, Recon loss: 26.363\n",
      "[3/10] - time: 0.42, Recon loss: 26.182\n",
      "[4/10] - time: 0.42, Recon loss: 24.677\n",
      "[5/10] - time: 0.42, Recon loss: 23.091\n",
      "[6/10] - time: 0.42, Recon loss: 25.020\n",
      "[7/10] - time: 0.42, Recon loss: 24.514\n",
      "[8/10] - time: 0.42, Recon loss: 22.543\n",
      "[9/10] - time: 0.42, Recon loss: 21.546\n",
      "[10/10] - time: 0.42, Recon loss: 22.108\n"
     ]
    }
   ],
   "source": [
    "print('Pre-training start!')\n",
    "start_time = time.time()\n",
    "for epoch in range(pre_train_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    Recon_losses = []\n",
    "    for x, _ in train_loader_src:\n",
    "        x = x.to(device)\n",
    "\n",
    "        # train generator G\n",
    "        G_optimizer.zero_grad()\n",
    "\n",
    "        x_feature = VGG((x + 1) / 2)\n",
    "        G_ = G(x)\n",
    "        G_feature = VGG((G_ + 1) / 2)\n",
    "\n",
    "        Recon_loss = 10 * L1_loss(G_feature, x_feature.detach())\n",
    "        Recon_losses.append(Recon_loss.item())\n",
    "        pre_train_hist['Recon_loss'].append(Recon_loss.item())\n",
    "\n",
    "        Recon_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "        break\n",
    "\n",
    "    per_epoch_time = time.time() - epoch_start_time\n",
    "    pre_train_hist['per_epoch_time'].append(per_epoch_time)\n",
    "    print('[%d/%d] - time: %.2f, Recon loss: %.3f' % ((epoch + 1), pre_train_epoch, per_epoch_time, torch.mean(torch.FloatTensor(Recon_losses))))\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "pre_train_hist['total_time'].append(total_time)\n",
    "with open(os.path.join(name + '_results',  'pre_train_hist.pkl'), 'wb') as f:\n",
    "    pickle.dump(pre_train_hist, f)\n",
    "\n",
    "with torch.no_grad():\n",
    "    G.eval()\n",
    "    for n, (x, _) in enumerate(train_loader_src):\n",
    "        x = x.to(device)\n",
    "        G_recon = G(x)\n",
    "        result = torch.cat((x[0], G_recon[0]), 2)\n",
    "        path = os.path.join(name + '_results', 'Reconstruction', name + '_train_recon_' + str(n + 1) + '.png')\n",
    "        plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
    "        if n == 4:\n",
    "            break\n",
    "\n",
    "    for n, (x, _) in enumerate(test_loader_src):\n",
    "        x = x.to(device)\n",
    "        G_recon = G(x)\n",
    "        result = torch.cat((x[0], G_recon[0]), 2)\n",
    "        path = os.path.join(name + '_results', 'Reconstruction', name + '_test_recon_' + str(n + 1) + '.png')\n",
    "        plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
    "        if n == 4:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = {}\n",
    "train_hist['Disc_loss'] = []\n",
    "train_hist['Gen_loss'] = []\n",
    "train_hist['Con_loss'] = []\n",
    "train_hist['per_epoch_time'] = []\n",
    "train_hist['total_time'] = []\n",
    "train_hist['Gen_loss_one_epoch']=[]\n",
    "train_hist['Disc_loss_one_epoch']=[]\n",
    "train_hist['Con_loss_one_epoch']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start!\n",
      "[1/50] - time: 1239.92, Disc loss: 1.313, Gen loss: 1.846, Con loss: 8.588\n",
      "[2/50] - time: 1239.15, Disc loss: 0.792, Gen loss: 2.150, Con loss: 6.918\n",
      "[3/50] - time: 1239.31, Disc loss: 0.618, Gen loss: 2.665, Con loss: 7.291\n",
      "[4/50] - time: 1238.95, Disc loss: 0.557, Gen loss: 2.914, Con loss: 7.643\n",
      "[5/50] - time: 1238.71, Disc loss: 0.577, Gen loss: 2.784, Con loss: 7.788\n",
      "[6/50] - time: 1238.82, Disc loss: 0.468, Gen loss: 3.021, Con loss: 8.066\n",
      "[7/50] - time: 1238.73, Disc loss: 0.413, Gen loss: 3.151, Con loss: 8.266\n",
      "[8/50] - time: 1238.63, Disc loss: 0.356, Gen loss: 3.365, Con loss: 8.512\n",
      "[9/50] - time: 1238.43, Disc loss: 0.301, Gen loss: 3.653, Con loss: 8.766\n",
      "[10/50] - time: 1238.35, Disc loss: 0.406, Gen loss: 3.578, Con loss: 9.021\n",
      "[11/50] - time: 1238.73, Disc loss: 0.576, Gen loss: 2.986, Con loss: 8.877\n",
      "[12/50] - time: 1238.84, Disc loss: 0.531, Gen loss: 3.078, Con loss: 9.016\n",
      "[13/50] - time: 1238.53, Disc loss: 0.441, Gen loss: 3.349, Con loss: 9.114\n",
      "[14/50] - time: 1238.49, Disc loss: 0.324, Gen loss: 3.871, Con loss: 8.741\n",
      "[15/50] - time: 1238.42, Disc loss: 0.293, Gen loss: 3.804, Con loss: 9.077\n",
      "[16/50] - time: 1238.55, Disc loss: 0.247, Gen loss: 4.080, Con loss: 9.277\n",
      "[17/50] - time: 1238.22, Disc loss: 0.126, Gen loss: 4.881, Con loss: 8.098\n",
      "[18/50] - time: 1238.61, Disc loss: 0.141, Gen loss: 5.759, Con loss: 8.764\n",
      "[19/50] - time: 1238.69, Disc loss: 0.507, Gen loss: 2.949, Con loss: 8.504\n",
      "[20/50] - time: 1238.57, Disc loss: 0.401, Gen loss: 3.540, Con loss: 8.584\n",
      "[21/50] - time: 1238.67, Disc loss: 0.422, Gen loss: 3.307, Con loss: 9.043\n",
      "[22/50] - time: 1238.54, Disc loss: 0.383, Gen loss: 3.513, Con loss: 8.971\n",
      "[23/50] - time: 1238.53, Disc loss: 0.400, Gen loss: 3.441, Con loss: 9.159\n",
      "[24/50] - time: 1239.29, Disc loss: 0.479, Gen loss: 3.199, Con loss: 9.441\n",
      "[25/50] - time: 1239.24, Disc loss: 0.384, Gen loss: 3.512, Con loss: 8.805\n",
      "[26/50] - time: 1239.04, Disc loss: 0.399, Gen loss: 2.491, Con loss: 9.394\n",
      "[27/50] - time: 1239.01, Disc loss: 0.360, Gen loss: 2.706, Con loss: 9.341\n",
      "[28/50] - time: 1238.84, Disc loss: 0.383, Gen loss: 2.687, Con loss: 9.513\n",
      "[29/50] - time: 1238.71, Disc loss: 0.459, Gen loss: 2.507, Con loss: 9.223\n",
      "[30/50] - time: 1238.66, Disc loss: 0.368, Gen loss: 2.754, Con loss: 8.436\n",
      "[31/50] - time: 1238.64, Disc loss: 0.418, Gen loss: 2.643, Con loss: 9.053\n",
      "[32/50] - time: 1238.51, Disc loss: 0.438, Gen loss: 2.670, Con loss: 8.987\n",
      "[33/50] - time: 1238.68, Disc loss: 0.428, Gen loss: 2.570, Con loss: 9.412\n"
     ]
    }
   ],
   "source": [
    "print('training start!')\n",
    "start_time = time.time()\n",
    "real = torch.ones(batch_size, 1, input_size // 4, input_size // 4).to(device)\n",
    "fake = torch.zeros(batch_size, 1, input_size // 4, input_size // 4).to(device)\n",
    "for epoch in range(train_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    G.train()\n",
    "    G_scheduler.step()\n",
    "    D_scheduler.step()\n",
    "    Disc_losses = []\n",
    "    Gen_losses = []\n",
    "    Con_losses = []\n",
    "    for (x, _), (y, _) in zip(train_loader_src, train_loader_tgt):\n",
    "        e = y[:, :, :, input_size:]\n",
    "        y = y[:, :, :, :input_size]\n",
    "        x, y, e = x.to(device), y.to(device), e.to(device)\n",
    "\n",
    "        # train D\n",
    "        D_optimizer.zero_grad()\n",
    "\n",
    "        D_real = D(y)\n",
    "        D_real_loss = BCE_loss(D_real, real)\n",
    "\n",
    "        G_ = G(x)\n",
    "        D_fake = D(G_)\n",
    "        D_fake_loss = BCE_loss(D_fake, fake)\n",
    "\n",
    "        D_edge = D(e)\n",
    "        D_edge_loss = BCE_loss(D_edge, fake)\n",
    "\n",
    "        Disc_loss = D_real_loss + D_fake_loss + D_edge_loss\n",
    "        Disc_losses.append(Disc_loss.item())\n",
    "        train_hist['Disc_loss'].append(Disc_loss.item())\n",
    "\n",
    "        Disc_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        # train G\n",
    "        G_optimizer.zero_grad()\n",
    "\n",
    "        G_ = G(x)\n",
    "        D_fake = D(G_)\n",
    "        D_fake_loss = BCE_loss(D_fake, real)\n",
    "\n",
    "        x_feature = VGG((x + 1) / 2)\n",
    "        G_feature = VGG((G_ + 1) / 2)\n",
    "        Con_loss = con_lambda * L1_loss(G_feature, x_feature.detach())\n",
    "\n",
    "#         Gen_loss = D_fake_loss + Con_loss\n",
    "#         Gen_loss = D_fake_loss\n",
    "        Gen_loss = D_fake_loss + 0.5 * Con_loss\n",
    "\n",
    "        Gen_losses.append(D_fake_loss.item())\n",
    "        train_hist['Gen_loss'].append(D_fake_loss.item())\n",
    "        Con_losses.append(Con_loss.item())\n",
    "        train_hist['Con_loss'].append(Con_loss.item())\n",
    "\n",
    "        Gen_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "\n",
    "    per_epoch_time = time.time() - epoch_start_time\n",
    "    train_hist['per_epoch_time'].append(per_epoch_time)\n",
    "    \n",
    "    Gen_loss_avg = torch.mean(torch.FloatTensor(Gen_losses))\n",
    "    Con_loss_avg = torch.mean(torch.FloatTensor(Con_losses))\n",
    "    Disc_loss_avg =  torch.mean(torch.FloatTensor(Disc_losses))\n",
    "    \n",
    "    train_hist['Gen_loss_one_epoch'].append(Gen_loss_avg)\n",
    "    train_hist['Disc_loss_one_epoch'].append(Disc_loss_avg)\n",
    "    train_hist['Con_loss_one_epoch'].append(Con_loss_avg)\n",
    "    \n",
    "    print(\n",
    "    '[%d/%d] - time: %.2f, Disc loss: %.3f, Gen loss: %.3f, Con loss: %.3f' % ((epoch + 1), train_epoch, per_epoch_time, Disc_loss_avg, Gen_loss_avg, Con_loss_avg))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        G.eval()\n",
    "        for n, (x, _) in enumerate(train_loader_src):\n",
    "            x = x.to(device)\n",
    "            G_recon = G(x)\n",
    "            result = torch.cat((x[0], G_recon[0]), 2)\n",
    "            path = os.path.join(name + '_results', 'Transfer', str(epoch+1) + '_epoch_' + name + '_train_' + str(n + 1) + '.png')\n",
    "            plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
    "            if n == 4:\n",
    "                break\n",
    "\n",
    "        for n, (x, _) in enumerate(test_loader_src):\n",
    "            x = x.to(device)\n",
    "            G_recon = G(x)\n",
    "            result = torch.cat((x[0], G_recon[0]), 2)\n",
    "            path = os.path.join(name + '_results', 'Transfer', str(epoch+1) + '_epoch_' + name + '_test_' + str(n + 1) + '.png')\n",
    "            plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
    "            if n == 4:\n",
    "                break\n",
    "\n",
    "        torch.save(G.state_dict(), os.path.join(name + '_results', 'generator_latest.pkl'))\n",
    "        torch.save(D.state_dict(), os.path.join(name + '_results', 'discriminator_latest.pkl'))\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "train_hist['total_time'].append(total_time)\n",
    "\n",
    "print(\"Avg one epoch time: %.2f, total %d epochs time: %.2f\" % (torch.mean(torch.FloatTensor(train_hist['per_epoch_time'])), train_epoch, total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f137ce403c8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_hist['Gen_loss'])\n",
    "plt.plot(train_hist['Disc_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G.state_dict(), os.path.join(name + '_results',  'generator_param.pkl'))\n",
    "torch.save(D.state_dict(), os.path.join(name + '_results',  'discriminator_param.pkl'))\n",
    "with open(os.path.join(name + '_results',  'train_hist.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_hist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_view = torch.load(os.path.join(name + '_results',  'generator_param.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('convs.0.weight',\n",
       "              tensor([[[[ 1.5837e-02,  5.5716e-03,  2.2361e-02],\n",
       "                        [-4.1403e-03,  2.1237e-02,  1.7914e-03],\n",
       "                        [-1.7184e-02,  1.9488e-02,  1.5258e-02]],\n",
       "              \n",
       "                       [[-2.4625e-02,  7.1820e-04,  2.2343e-02],\n",
       "                        [ 1.4765e-02, -2.4119e-02,  9.5952e-03],\n",
       "                        [ 4.8353e-02,  7.2604e-03,  1.6212e-02]],\n",
       "              \n",
       "                       [[-3.8617e-02, -2.2787e-02,  6.1015e-03],\n",
       "                        [-1.8316e-02,  7.6806e-03,  9.7825e-03],\n",
       "                        [-1.6106e-02,  9.1911e-04, -1.0556e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.5714e-02, -2.1110e-02,  3.4113e-06],\n",
       "                        [ 1.2102e-02,  1.1570e-02,  1.5014e-02],\n",
       "                        [ 1.2348e-02, -5.8596e-03,  2.0600e-02]],\n",
       "              \n",
       "                       [[ 7.0174e-03, -8.1979e-03,  2.9815e-02],\n",
       "                        [ 1.7954e-02,  1.9829e-02,  1.2723e-02],\n",
       "                        [ 7.3255e-03, -1.0527e-02, -3.4564e-02]],\n",
       "              \n",
       "                       [[-3.9045e-02, -2.3609e-02, -2.0781e-02],\n",
       "                        [-3.5449e-03, -1.8154e-02, -3.8977e-03],\n",
       "                        [-3.0511e-03, -3.6914e-02, -2.2485e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4330e-02,  2.3383e-02, -1.2477e-02],\n",
       "                        [-1.0595e-02,  1.6658e-02, -5.6116e-03],\n",
       "                        [-5.7629e-03, -9.2043e-03, -2.1974e-02]],\n",
       "              \n",
       "                       [[-2.7776e-03,  4.4000e-03,  3.6617e-02],\n",
       "                        [ 1.8588e-02, -1.2034e-03,  1.0672e-02],\n",
       "                        [-1.6515e-02, -1.5102e-02,  2.2182e-02]],\n",
       "              \n",
       "                       [[-1.1701e-02,  7.2087e-03, -6.6996e-03],\n",
       "                        [-3.5272e-02, -4.9528e-03,  1.1569e-02],\n",
       "                        [ 6.2364e-03, -6.6022e-03,  2.2967e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.3298e-03, -2.0427e-02, -3.9792e-03],\n",
       "                        [-3.8798e-02,  9.6119e-03,  3.8970e-03],\n",
       "                        [ 5.7734e-03,  1.9109e-02,  1.3146e-02]],\n",
       "              \n",
       "                       [[ 2.7847e-02, -1.0846e-02,  1.1276e-03],\n",
       "                        [-1.1345e-02, -5.2779e-04, -2.7129e-02],\n",
       "                        [ 1.7646e-02, -1.7175e-03,  2.8792e-02]],\n",
       "              \n",
       "                       [[-7.2863e-03,  1.3293e-02, -2.8088e-02],\n",
       "                        [ 3.3121e-03, -6.9049e-03,  6.5960e-03],\n",
       "                        [-1.4945e-02, -6.2135e-03, -7.3857e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1046e-02, -2.7175e-03,  1.4095e-02],\n",
       "                        [-8.9420e-03, -7.1905e-03, -1.0471e-02],\n",
       "                        [ 1.1769e-03,  3.3497e-03, -6.8096e-04]],\n",
       "              \n",
       "                       [[ 1.6582e-02, -2.0580e-02,  1.8502e-02],\n",
       "                        [ 4.3871e-03, -5.3600e-02, -2.6688e-02],\n",
       "                        [-1.0917e-02, -7.2693e-03, -2.6432e-02]],\n",
       "              \n",
       "                       [[ 2.2066e-03, -1.3309e-02, -1.8073e-02],\n",
       "                        [-1.8579e-02, -8.0211e-03,  3.9843e-04],\n",
       "                        [-1.8944e-02, -4.5581e-03, -4.9573e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.8686e-02, -8.3156e-03, -1.4574e-02],\n",
       "                        [-2.2265e-02, -4.3542e-02, -4.4985e-02],\n",
       "                        [-1.1370e-02,  3.3013e-03, -1.7633e-02]],\n",
       "              \n",
       "                       [[ 2.1262e-02,  1.3174e-02,  2.1188e-02],\n",
       "                        [ 1.9772e-02,  2.8792e-02,  4.4629e-02],\n",
       "                        [-3.3395e-02,  9.8043e-03, -9.8154e-03]],\n",
       "              \n",
       "                       [[ 4.8255e-02,  1.2239e-02, -2.3607e-02],\n",
       "                        [-3.7466e-02, -1.2597e-02, -2.6613e-02],\n",
       "                        [ 5.7442e-04,  2.1302e-02, -2.2903e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.6106e-02,  1.6036e-02, -1.5552e-03],\n",
       "                        [-8.3731e-03,  1.0734e-02, -2.4168e-02],\n",
       "                        [ 3.3462e-02,  3.5969e-02, -4.8053e-03]],\n",
       "              \n",
       "                       [[ 8.1434e-03, -1.9237e-02, -5.2619e-03],\n",
       "                        [-1.5214e-02,  4.2514e-02, -1.2739e-02],\n",
       "                        [ 3.7183e-02, -2.8589e-02,  3.1357e-03]],\n",
       "              \n",
       "                       [[-4.1546e-05, -1.7741e-02,  1.4086e-03],\n",
       "                        [ 1.5314e-02,  1.0696e-02, -3.9329e-02],\n",
       "                        [-2.6442e-03,  3.0182e-02, -3.4274e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.4834e-02,  1.2367e-02,  1.7564e-03],\n",
       "                        [-7.2122e-03, -3.4884e-02, -1.9584e-02],\n",
       "                        [ 1.5026e-02, -2.3375e-02, -2.2640e-02]],\n",
       "              \n",
       "                       [[ 4.2438e-02,  1.9870e-02,  4.1647e-03],\n",
       "                        [-3.7282e-02, -5.7309e-03, -2.0009e-02],\n",
       "                        [ 1.6406e-02,  7.9486e-03,  4.0190e-03]],\n",
       "              \n",
       "                       [[ 4.6463e-02, -2.3713e-02, -7.7309e-03],\n",
       "                        [-2.0237e-02,  1.2153e-02, -3.4234e-02],\n",
       "                        [-3.5988e-03, -2.1306e-03, -7.1882e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0649e-02, -2.3349e-02, -9.0676e-03],\n",
       "                        [-1.7762e-02, -2.1168e-02,  2.0583e-03],\n",
       "                        [-1.7598e-02,  1.2972e-02, -1.5427e-03]],\n",
       "              \n",
       "                       [[-2.2169e-02, -1.2720e-02, -9.4086e-04],\n",
       "                        [ 2.7784e-03,  2.1077e-02, -8.6437e-04],\n",
       "                        [-9.6291e-03, -2.2043e-02,  5.0293e-02]],\n",
       "              \n",
       "                       [[ 3.2819e-02, -3.0097e-02,  2.2700e-02],\n",
       "                        [-1.5849e-02, -1.9711e-02,  4.6121e-02],\n",
       "                        [ 1.2081e-02, -1.4673e-03,  1.3762e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4343e-02, -8.7209e-03, -2.6896e-02],\n",
       "                        [-9.6415e-03,  3.4580e-02,  1.0165e-02],\n",
       "                        [-5.3846e-02,  1.4309e-02,  3.8714e-03]],\n",
       "              \n",
       "                       [[ 1.0837e-02,  3.6182e-03,  2.0396e-02],\n",
       "                        [-1.4219e-02, -1.6418e-02, -3.0470e-03],\n",
       "                        [ 1.7163e-03,  1.6401e-02, -4.3658e-03]],\n",
       "              \n",
       "                       [[ 7.2075e-03, -2.2724e-02,  1.1201e-02],\n",
       "                        [ 2.6292e-03, -5.3360e-03,  1.1989e-02],\n",
       "                        [-6.2895e-03, -1.7979e-02,  1.3066e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.0477e-02, -2.5846e-02, -2.3309e-02],\n",
       "                        [-3.1845e-02,  2.1493e-02,  1.6596e-02],\n",
       "                        [-3.7823e-03,  4.6768e-03,  5.0476e-02]],\n",
       "              \n",
       "                       [[ 3.9711e-03, -3.8655e-03, -1.6967e-02],\n",
       "                        [-8.4462e-03, -1.4435e-02, -2.6546e-02],\n",
       "                        [ 8.0677e-04,  1.4860e-02,  2.1260e-02]],\n",
       "              \n",
       "                       [[-8.9187e-03,  1.6268e-02,  3.4589e-02],\n",
       "                        [-3.0804e-03, -1.5774e-02, -1.0321e-03],\n",
       "                        [-4.5725e-02,  1.1537e-02,  1.0065e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.0300e-03, -8.2859e-03,  1.4473e-02],\n",
       "                        [ 4.5473e-02,  4.1378e-03, -2.3637e-02],\n",
       "                        [-1.2330e-02,  1.6238e-02, -1.9554e-02]],\n",
       "              \n",
       "                       [[ 2.7321e-02,  1.7001e-02,  9.8521e-03],\n",
       "                        [ 1.2466e-02,  1.2139e-02, -3.2289e-02],\n",
       "                        [ 9.4977e-04,  9.9446e-03,  2.4332e-02]],\n",
       "              \n",
       "                       [[ 1.7300e-02,  1.3096e-02, -1.1033e-02],\n",
       "                        [-1.8685e-02,  2.2542e-02, -2.1972e-02],\n",
       "                        [ 2.7417e-02,  3.9991e-02,  5.2706e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1364e-04, -1.9183e-04,  5.1626e-03],\n",
       "                        [ 4.1182e-03,  2.2321e-02, -1.0791e-02],\n",
       "                        [-1.9582e-02,  2.5142e-02,  7.4781e-03]],\n",
       "              \n",
       "                       [[-2.1607e-02,  2.8469e-03,  4.7343e-02],\n",
       "                        [ 1.6334e-02, -3.7189e-02, -4.9735e-03],\n",
       "                        [-3.6461e-02, -9.0528e-03, -4.3909e-02]],\n",
       "              \n",
       "                       [[-4.3405e-03,  1.7533e-02,  3.1417e-02],\n",
       "                        [ 1.9720e-02, -1.6210e-02,  2.0351e-02],\n",
       "                        [-3.2795e-02, -1.1640e-02,  3.0026e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0264e-02,  1.1607e-02,  1.8141e-02],\n",
       "                        [ 1.2342e-02,  3.0518e-02, -8.4862e-03],\n",
       "                        [-4.0602e-03, -7.0729e-03, -4.3818e-05]],\n",
       "              \n",
       "                       [[-1.4598e-02, -1.8836e-02, -8.1282e-04],\n",
       "                        [-4.5485e-03,  2.7270e-02,  2.5414e-02],\n",
       "                        [ 1.8338e-02,  2.3311e-02,  1.3186e-02]],\n",
       "              \n",
       "                       [[ 7.9730e-03, -5.7262e-03, -1.2197e-02],\n",
       "                        [-2.3475e-02, -6.6214e-03, -7.0980e-03],\n",
       "                        [-3.3921e-02,  2.8815e-02,  3.7233e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.3828e-03, -3.3951e-02, -5.9118e-03],\n",
       "                        [ 1.4800e-02,  2.0933e-02,  2.2886e-02],\n",
       "                        [-6.6742e-03,  1.1142e-02,  1.0374e-02]],\n",
       "              \n",
       "                       [[-1.9424e-02,  1.7594e-02, -5.0250e-02],\n",
       "                        [-1.0640e-02,  2.1592e-02,  5.1572e-03],\n",
       "                        [-1.5512e-03, -2.4361e-02, -8.8650e-03]],\n",
       "              \n",
       "                       [[ 8.1335e-03, -4.8611e-03, -1.1122e-02],\n",
       "                        [-3.5770e-02, -1.7579e-02,  2.1561e-02],\n",
       "                        [ 2.8000e-02, -3.0147e-02, -2.4652e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6216e-02,  8.9737e-03,  1.0691e-02],\n",
       "                        [-1.1187e-02, -6.3990e-03,  1.0734e-02],\n",
       "                        [-9.7406e-03,  2.1392e-02, -6.6022e-03]],\n",
       "              \n",
       "                       [[ 9.6759e-03, -3.9088e-03, -7.2418e-04],\n",
       "                        [-1.9529e-02, -1.9772e-03,  3.1753e-04],\n",
       "                        [-1.5620e-02, -3.9232e-02,  3.0923e-02]],\n",
       "              \n",
       "                       [[ 1.9631e-02, -1.4588e-02,  8.3433e-03],\n",
       "                        [ 9.9812e-03,  5.4509e-03, -1.6099e-02],\n",
       "                        [-2.3538e-02, -1.1390e-02,  1.8095e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9072e-02,  1.0909e-02, -2.3923e-02],\n",
       "                        [-1.3051e-02,  3.9030e-02,  3.1939e-03],\n",
       "                        [-1.7675e-02,  4.4314e-03, -1.4855e-02]],\n",
       "              \n",
       "                       [[-5.3826e-03, -3.7757e-02, -1.3262e-03],\n",
       "                        [ 3.3547e-02, -1.0046e-02,  1.4935e-02],\n",
       "                        [-5.0361e-04,  2.6709e-02,  1.3989e-02]],\n",
       "              \n",
       "                       [[-1.1270e-02, -2.2181e-03,  1.3513e-02],\n",
       "                        [-1.1908e-02,  3.5507e-03, -7.4825e-03],\n",
       "                        [ 3.2004e-03, -1.6237e-02,  9.7896e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2119e-02, -1.4074e-02,  2.7082e-03],\n",
       "                        [-1.5334e-02,  7.9744e-03, -2.6409e-02],\n",
       "                        [-1.0430e-02, -1.3862e-02,  7.1304e-04]],\n",
       "              \n",
       "                       [[-3.6022e-02,  1.8163e-02,  3.5983e-02],\n",
       "                        [-6.6753e-03, -4.6043e-03,  4.0417e-02],\n",
       "                        [-1.7964e-02, -2.5125e-02, -9.5920e-03]],\n",
       "              \n",
       "                       [[-5.3558e-02,  7.1153e-03, -2.5752e-03],\n",
       "                        [-4.7742e-03,  4.6455e-03, -8.4945e-03],\n",
       "                        [ 1.2477e-03, -3.8684e-02,  1.4671e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8570e-04,  1.3204e-02,  3.0121e-02],\n",
       "                        [ 9.4546e-03, -1.3028e-02,  2.6792e-02],\n",
       "                        [-2.4222e-02,  7.0884e-03,  7.1828e-03]],\n",
       "              \n",
       "                       [[ 1.3722e-02, -1.4415e-02, -6.3908e-04],\n",
       "                        [ 5.9562e-03, -1.3452e-02, -6.7666e-03],\n",
       "                        [ 2.8010e-02,  2.8352e-02, -4.3384e-02]],\n",
       "              \n",
       "                       [[ 3.0480e-02,  3.0524e-02, -1.3496e-02],\n",
       "                        [ 7.3440e-03, -1.7494e-02, -1.6173e-02],\n",
       "                        [-1.1810e-02,  5.8710e-03, -4.3794e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.5816e-02, -3.8288e-02,  3.5001e-02],\n",
       "                        [-1.6921e-02,  1.0024e-02,  2.6377e-03],\n",
       "                        [ 2.3679e-02,  3.4956e-03,  9.9510e-03]],\n",
       "              \n",
       "                       [[ 3.8946e-02,  6.8959e-03, -8.0551e-03],\n",
       "                        [ 7.9305e-04,  5.9391e-03,  5.6790e-03],\n",
       "                        [-4.5756e-03, -3.0162e-03,  2.1381e-02]],\n",
       "              \n",
       "                       [[-1.8068e-03, -2.7317e-03,  6.8496e-04],\n",
       "                        [-2.4571e-02, -1.0058e-02,  2.3202e-02],\n",
       "                        [-1.5562e-02,  2.7062e-03,  1.4113e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1627e-03,  1.9596e-02,  1.5440e-02],\n",
       "                        [-1.4980e-02, -9.0682e-03, -1.8549e-02],\n",
       "                        [ 7.6862e-03, -1.9373e-02, -6.9674e-03]],\n",
       "              \n",
       "                       [[ 1.7200e-02,  4.4572e-02,  1.2653e-02],\n",
       "                        [ 2.5340e-02,  2.6628e-02,  5.1146e-03],\n",
       "                        [ 7.2156e-03,  4.6065e-03,  3.3946e-02]],\n",
       "              \n",
       "                       [[ 7.4539e-03,  7.4094e-03, -2.5921e-02],\n",
       "                        [-9.4852e-03, -3.2252e-03, -7.5970e-03],\n",
       "                        [-2.1965e-02, -6.9928e-03, -4.5895e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1556e-02,  3.4074e-03, -4.0086e-02],\n",
       "                        [-3.5928e-02,  4.1663e-03,  1.7400e-02],\n",
       "                        [ 7.4449e-03, -8.4933e-03, -3.3985e-02]],\n",
       "              \n",
       "                       [[ 2.5675e-02, -4.2611e-02,  2.7799e-03],\n",
       "                        [ 3.3970e-02,  2.4151e-03,  4.5675e-03],\n",
       "                        [-1.2116e-03, -1.0177e-02,  1.3497e-02]],\n",
       "              \n",
       "                       [[ 2.4624e-02, -8.8087e-03, -1.8038e-02],\n",
       "                        [ 1.7555e-03, -2.0683e-03,  3.5481e-03],\n",
       "                        [ 1.1520e-02, -4.0097e-02, -1.6224e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.6042e-03, -5.7483e-03,  1.5852e-02],\n",
       "                        [-1.2473e-02,  4.9937e-02,  1.7429e-02],\n",
       "                        [ 1.9335e-02,  2.4252e-02,  2.7132e-03]],\n",
       "              \n",
       "                       [[-5.8158e-03,  4.0707e-02, -1.9437e-02],\n",
       "                        [-8.1287e-03,  1.9862e-03, -3.7282e-03],\n",
       "                        [-2.0457e-02, -2.9011e-02, -1.0872e-04]],\n",
       "              \n",
       "                       [[-2.6828e-02,  4.1706e-04, -9.4599e-04],\n",
       "                        [-3.7220e-02, -2.5841e-03, -2.8124e-03],\n",
       "                        [-1.7565e-02,  3.1761e-02, -1.0836e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.5010e-02,  1.4532e-02,  1.6180e-02],\n",
       "                        [ 2.0877e-02,  5.1180e-02, -1.3499e-02],\n",
       "                        [-2.4068e-03,  4.4496e-02, -2.7299e-02]],\n",
       "              \n",
       "                       [[ 1.4542e-02, -1.5667e-02, -2.9627e-02],\n",
       "                        [-7.3373e-03, -1.2646e-02,  1.7130e-02],\n",
       "                        [-5.1900e-04, -2.0507e-02,  1.3643e-02]],\n",
       "              \n",
       "                       [[-2.0063e-02, -1.4964e-02, -1.2863e-02],\n",
       "                        [ 1.6435e-03, -1.9878e-02, -1.4403e-02],\n",
       "                        [-6.8756e-03,  3.6214e-02, -2.7528e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.1858e-02, -2.0212e-03,  3.1231e-02],\n",
       "                        [ 2.4283e-02,  8.2441e-03, -2.3934e-02],\n",
       "                        [-2.3422e-02, -1.3601e-02,  5.7752e-03]],\n",
       "              \n",
       "                       [[-9.7793e-04,  1.6697e-02, -8.4958e-03],\n",
       "                        [ 3.7325e-02, -3.3438e-02,  1.4254e-02],\n",
       "                        [ 4.6056e-02,  2.1494e-02,  2.7166e-02]],\n",
       "              \n",
       "                       [[-3.8566e-02,  1.3815e-02,  2.5075e-02],\n",
       "                        [-1.5956e-02, -2.8861e-02,  2.2529e-02],\n",
       "                        [-1.9170e-03,  2.1119e-02,  2.0246e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.8716e-03,  3.1270e-02, -7.2448e-04],\n",
       "                        [ 6.0954e-03, -6.6840e-03, -1.6545e-02],\n",
       "                        [ 2.3292e-02,  3.5197e-02,  1.4020e-02]],\n",
       "              \n",
       "                       [[-9.4848e-03,  4.3002e-02, -1.0078e-02],\n",
       "                        [ 1.3722e-02, -9.9774e-03, -7.6784e-03],\n",
       "                        [ 1.8455e-02, -2.4081e-02,  1.6869e-02]],\n",
       "              \n",
       "                       [[-1.2991e-02,  6.6195e-04,  1.0412e-02],\n",
       "                        [-2.6429e-02,  9.9340e-03,  3.5849e-03],\n",
       "                        [ 1.4652e-02, -4.5224e-03,  2.3214e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3921e-02,  4.7719e-04, -2.1347e-02],\n",
       "                        [-1.0351e-03, -7.2072e-03,  6.4655e-03],\n",
       "                        [-2.1855e-02, -7.0416e-03,  1.7759e-03]],\n",
       "              \n",
       "                       [[-1.5314e-02,  3.4862e-02, -7.2535e-04],\n",
       "                        [ 1.3714e-02,  5.6872e-03,  2.7444e-02],\n",
       "                        [ 1.6092e-02,  2.4188e-02, -3.4779e-02]],\n",
       "              \n",
       "                       [[-7.2256e-03, -4.4949e-02, -1.2199e-02],\n",
       "                        [-1.1590e-02,  1.5187e-02, -9.6938e-05],\n",
       "                        [-6.8622e-03, -1.7594e-02,  1.8073e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.8253e-03, -2.3745e-02, -1.1471e-02],\n",
       "                        [-8.8904e-05, -4.9176e-03, -1.7002e-02],\n",
       "                        [-1.2919e-02, -4.3546e-04,  3.8618e-02]],\n",
       "              \n",
       "                       [[ 2.0236e-02,  3.7631e-03,  9.9189e-03],\n",
       "                        [ 1.9932e-02, -9.5462e-03,  6.3907e-04],\n",
       "                        [-4.0711e-03, -1.1309e-02,  1.3326e-02]],\n",
       "              \n",
       "                       [[ 2.0963e-02,  5.7777e-03,  7.0196e-04],\n",
       "                        [-4.6763e-02, -3.7217e-03,  4.0084e-04],\n",
       "                        [-2.8678e-02, -3.2825e-02,  3.3868e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.9623e-03,  1.6874e-02,  9.0842e-03],\n",
       "                        [ 5.6581e-03, -1.5445e-02,  8.6140e-04],\n",
       "                        [-1.4510e-02, -4.7015e-03,  3.4437e-03]],\n",
       "              \n",
       "                       [[ 7.3375e-03, -2.6822e-03, -1.8393e-02],\n",
       "                        [ 3.2278e-02,  1.7467e-02,  1.7223e-02],\n",
       "                        [-3.6473e-02,  8.6902e-03,  2.2710e-02]],\n",
       "              \n",
       "                       [[ 1.6345e-02,  1.2979e-02,  5.6039e-03],\n",
       "                        [-2.5967e-02,  2.1211e-02, -2.3138e-02],\n",
       "                        [-5.8536e-03, -3.9434e-02, -1.0932e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4691e-02, -7.5375e-03,  2.2442e-02],\n",
       "                        [ 6.0080e-03,  3.4118e-02, -1.5446e-02],\n",
       "                        [-1.4109e-02,  2.9232e-02,  5.0795e-03]],\n",
       "              \n",
       "                       [[ 1.4046e-02, -1.5721e-03,  3.1522e-02],\n",
       "                        [ 1.6736e-02, -4.1541e-02,  2.4878e-02],\n",
       "                        [-2.1905e-02, -4.4399e-02,  4.1870e-02]],\n",
       "              \n",
       "                       [[ 7.8769e-03, -1.3905e-02,  3.3992e-03],\n",
       "                        [ 2.6274e-02, -1.0305e-02,  3.1515e-02],\n",
       "                        [ 5.3207e-03, -1.9235e-02, -1.2109e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9295e-02, -1.3062e-02, -1.1976e-03],\n",
       "                        [ 3.5845e-02,  1.0401e-02,  5.6732e-02],\n",
       "                        [ 2.5325e-02,  6.5273e-02,  6.5111e-04]],\n",
       "              \n",
       "                       [[ 2.1160e-02,  2.5341e-02,  9.5686e-03],\n",
       "                        [ 1.5748e-02, -7.5212e-04,  1.4436e-03],\n",
       "                        [ 5.5020e-03, -3.9382e-02, -4.9115e-03]],\n",
       "              \n",
       "                       [[ 1.6589e-02, -1.3484e-02,  2.4526e-02],\n",
       "                        [-1.8575e-02,  1.0738e-02, -1.3543e-03],\n",
       "                        [-2.8530e-02,  2.7413e-02, -1.0358e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.1769e-02, -1.6010e-02,  6.2736e-03],\n",
       "                        [ 7.1019e-03,  2.0922e-03,  1.5174e-02],\n",
       "                        [ 5.8692e-03,  5.4827e-03, -8.5944e-03]],\n",
       "              \n",
       "                       [[ 1.1542e-02,  3.8515e-03,  1.8829e-02],\n",
       "                        [ 9.5453e-03,  2.2512e-03,  2.6306e-02],\n",
       "                        [-1.6072e-02,  1.5366e-02,  4.1768e-02]],\n",
       "              \n",
       "                       [[ 2.1822e-02, -1.0606e-03, -3.5764e-03],\n",
       "                        [ 2.3218e-02,  1.6058e-02, -8.3186e-03],\n",
       "                        [ 1.2365e-02,  2.2511e-02, -1.1479e-02]]]])),\n",
       "             ('convs.0.bias',\n",
       "              tensor([ 8.3648e-06,  1.5253e-06,  5.4511e-06, -8.2265e-06, -7.2504e-06,\n",
       "                      -4.3526e-06,  7.0171e-06,  6.6996e-06,  8.6284e-06, -4.2341e-06,\n",
       "                      -7.8364e-06, -7.8223e-06,  6.6062e-06, -6.8745e-06,  3.9376e-06,\n",
       "                       8.9862e-07,  6.4326e-06, -8.3696e-06, -7.8221e-06,  8.3846e-06,\n",
       "                       7.5897e-06,  6.0419e-06,  7.5345e-06,  4.8964e-06, -7.1576e-06,\n",
       "                       1.2551e-06, -5.1902e-06,  7.6345e-06, -8.0377e-06, -8.5009e-06,\n",
       "                       4.2150e-06,  7.1116e-06])),\n",
       "             ('convs.2.weight', tensor([[[[ 0.0129, -0.0136,  0.0019],\n",
       "                        [-0.0112,  0.0089, -0.0131],\n",
       "                        [-0.0273,  0.0190,  0.0072]],\n",
       "              \n",
       "                       [[-0.0144,  0.0176,  0.0129],\n",
       "                        [ 0.0148,  0.0410,  0.0202],\n",
       "                        [ 0.0073,  0.0084,  0.0261]],\n",
       "              \n",
       "                       [[ 0.0218, -0.0332,  0.0178],\n",
       "                        [-0.0189,  0.0025,  0.0245],\n",
       "                        [-0.0121, -0.0730,  0.0259]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0059,  0.0196,  0.0189],\n",
       "                        [-0.0080,  0.0014, -0.0319],\n",
       "                        [ 0.0025,  0.0002, -0.0090]],\n",
       "              \n",
       "                       [[ 0.0129, -0.0108, -0.0355],\n",
       "                        [ 0.0229, -0.0255, -0.0067],\n",
       "                        [ 0.0317, -0.0505,  0.0018]],\n",
       "              \n",
       "                       [[ 0.0142, -0.0173,  0.0133],\n",
       "                        [ 0.0069,  0.0117,  0.0155],\n",
       "                        [ 0.0049, -0.0043,  0.0396]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0056,  0.0483,  0.0005],\n",
       "                        [ 0.0157, -0.0076, -0.0236],\n",
       "                        [ 0.0209,  0.0120,  0.0093]],\n",
       "              \n",
       "                       [[-0.0143, -0.0084,  0.0331],\n",
       "                        [-0.0212, -0.0161, -0.0027],\n",
       "                        [ 0.0207, -0.0092, -0.0049]],\n",
       "              \n",
       "                       [[-0.0074, -0.0240, -0.0282],\n",
       "                        [ 0.0124,  0.0185,  0.0254],\n",
       "                        [ 0.0052, -0.0068, -0.0039]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0233, -0.0236,  0.0044],\n",
       "                        [-0.0147, -0.0004,  0.0158],\n",
       "                        [ 0.0233,  0.0263,  0.0029]],\n",
       "              \n",
       "                       [[ 0.0248,  0.0008,  0.0458],\n",
       "                        [-0.0170, -0.0057, -0.0190],\n",
       "                        [-0.0102, -0.0087,  0.0006]],\n",
       "              \n",
       "                       [[ 0.0075, -0.0064,  0.0369],\n",
       "                        [ 0.0048,  0.0181,  0.0099],\n",
       "                        [-0.0104, -0.0169,  0.0265]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0118,  0.0005, -0.0094],\n",
       "                        [ 0.0319, -0.0129, -0.0152],\n",
       "                        [-0.0044, -0.0095,  0.0093]],\n",
       "              \n",
       "                       [[ 0.0014,  0.0111, -0.0161],\n",
       "                        [-0.0073,  0.0281,  0.0087],\n",
       "                        [-0.0334, -0.0474,  0.0002]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0321,  0.0288],\n",
       "                        [-0.0035,  0.0136,  0.0171],\n",
       "                        [-0.0097, -0.0302, -0.0043]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0381, -0.0307,  0.0033],\n",
       "                        [-0.0065, -0.0024, -0.0199],\n",
       "                        [ 0.0157,  0.0014, -0.0167]],\n",
       "              \n",
       "                       [[ 0.0217, -0.0011, -0.0449],\n",
       "                        [ 0.0020, -0.0153,  0.0224],\n",
       "                        [-0.0343, -0.0096, -0.0127]],\n",
       "              \n",
       "                       [[ 0.0120, -0.0192, -0.0052],\n",
       "                        [-0.0208, -0.0061,  0.0003],\n",
       "                        [-0.0184, -0.0244,  0.0100]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0183, -0.0080, -0.0162],\n",
       "                        [ 0.0054, -0.0202, -0.0104],\n",
       "                        [-0.0271,  0.0290,  0.0119]],\n",
       "              \n",
       "                       [[-0.0265, -0.0258,  0.0048],\n",
       "                        [-0.0031, -0.0117,  0.0074],\n",
       "                        [-0.0048,  0.0105, -0.0089]],\n",
       "              \n",
       "                       [[ 0.0129, -0.0005,  0.0105],\n",
       "                        [ 0.0214,  0.0042, -0.0072],\n",
       "                        [-0.0055,  0.0038,  0.0124]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0222, -0.0057, -0.0058],\n",
       "                        [-0.0164, -0.0283,  0.0004],\n",
       "                        [ 0.0074,  0.0092,  0.0034]],\n",
       "              \n",
       "                       [[-0.0090, -0.0096, -0.0004],\n",
       "                        [-0.0008, -0.0014, -0.0095],\n",
       "                        [ 0.0407,  0.0094, -0.0041]],\n",
       "              \n",
       "                       [[ 0.0323,  0.0092, -0.0053],\n",
       "                        [-0.0069, -0.0094, -0.0202],\n",
       "                        [ 0.0151,  0.0092, -0.0240]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0144, -0.0262,  0.0107],\n",
       "                        [ 0.0066,  0.0303, -0.0282],\n",
       "                        [ 0.0097, -0.0090, -0.0091]],\n",
       "              \n",
       "                       [[ 0.0022, -0.0371, -0.0066],\n",
       "                        [ 0.0165, -0.0124, -0.0162],\n",
       "                        [-0.0109, -0.0024,  0.0356]],\n",
       "              \n",
       "                       [[-0.0073, -0.0196, -0.0170],\n",
       "                        [-0.0059,  0.0037, -0.0259],\n",
       "                        [-0.0046, -0.0137, -0.0135]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0011,  0.0002,  0.0564],\n",
       "                        [ 0.0213, -0.0017,  0.0563],\n",
       "                        [ 0.0034,  0.0235, -0.0329]],\n",
       "              \n",
       "                       [[-0.0068,  0.0015,  0.0104],\n",
       "                        [-0.0139, -0.0031, -0.0325],\n",
       "                        [ 0.0236,  0.0113,  0.0016]],\n",
       "              \n",
       "                       [[ 0.0045,  0.0218, -0.0007],\n",
       "                        [-0.0052,  0.0127,  0.0092],\n",
       "                        [-0.0230, -0.0416, -0.0050]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0193, -0.0127, -0.0229],\n",
       "                        [-0.0081, -0.0097,  0.0103],\n",
       "                        [ 0.0047, -0.0090,  0.0080]],\n",
       "              \n",
       "                       [[ 0.0226,  0.0140, -0.0147],\n",
       "                        [ 0.0077,  0.0036, -0.0257],\n",
       "                        [ 0.0035,  0.0074, -0.0164]],\n",
       "              \n",
       "                       [[-0.0041, -0.0039, -0.0498],\n",
       "                        [-0.0179,  0.0098,  0.0101],\n",
       "                        [-0.0143, -0.0233,  0.0313]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0047,  0.0086,  0.0086],\n",
       "                        [-0.0237, -0.0188,  0.0062],\n",
       "                        [-0.0138,  0.0385, -0.0165]],\n",
       "              \n",
       "                       [[-0.0099, -0.0132, -0.0117],\n",
       "                        [-0.0003,  0.0265,  0.0075],\n",
       "                        [-0.0172, -0.0182,  0.0263]],\n",
       "              \n",
       "                       [[-0.0542,  0.0192, -0.0015],\n",
       "                        [-0.0086, -0.0144,  0.0263],\n",
       "                        [-0.0179,  0.0166, -0.0019]]]])),\n",
       "             ('convs.2.bias',\n",
       "              tensor([ 4.0192e-06, -8.0399e-06, -5.2293e-06, -2.9591e-06, -7.9887e-06,\n",
       "                      -8.1574e-06, -3.2895e-06, -5.6689e-06, -3.5881e-06, -7.6229e-06,\n",
       "                       6.8577e-06,  7.6954e-06,  4.4277e-06,  6.4933e-06, -7.9416e-06,\n",
       "                       6.5013e-06,  8.7969e-07,  7.6490e-06,  8.0071e-06, -5.5015e-07,\n",
       "                      -6.0270e-06, -6.9061e-06,  5.2774e-06, -5.3888e-06, -8.2028e-06,\n",
       "                      -3.8870e-06,  8.3795e-06,  2.0819e-06,  3.3670e-06,  7.7684e-06,\n",
       "                       6.0117e-06, -5.6351e-07,  7.1849e-06,  8.4528e-06,  5.9789e-06,\n",
       "                       7.8706e-06,  6.3125e-06,  4.6123e-06,  5.3875e-06, -7.7948e-06,\n",
       "                       8.4803e-06,  1.1354e-06, -6.9481e-06,  3.4879e-06, -6.7637e-06,\n",
       "                      -7.4054e-06,  5.9255e-06, -6.4106e-07,  6.4012e-06, -7.8149e-06,\n",
       "                      -1.4060e-06,  6.7892e-06, -7.6435e-07,  4.0993e-06, -3.4416e-06,\n",
       "                       5.4776e-06, -8.4781e-06, -6.9273e-06, -8.0102e-06, -7.6616e-06,\n",
       "                      -6.1966e-09,  4.3854e-06,  7.9625e-06,  6.8103e-07])),\n",
       "             ('convs.4.weight', tensor([[[[ 0.0124, -0.0049,  0.0215],\n",
       "                        [ 0.0550, -0.0260, -0.0357],\n",
       "                        [ 0.0072, -0.0084, -0.0066]],\n",
       "              \n",
       "                       [[ 0.0129,  0.0102, -0.0085],\n",
       "                        [ 0.0167, -0.0159, -0.0258],\n",
       "                        [ 0.0132,  0.0080,  0.0149]],\n",
       "              \n",
       "                       [[ 0.0046, -0.0009, -0.0004],\n",
       "                        [-0.0242,  0.0177, -0.0291],\n",
       "                        [ 0.0204, -0.0063,  0.0162]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0201, -0.0086, -0.0137],\n",
       "                        [ 0.0033,  0.0046,  0.0107],\n",
       "                        [-0.0324,  0.0364,  0.0166]],\n",
       "              \n",
       "                       [[ 0.0212,  0.0046, -0.0121],\n",
       "                        [ 0.0021, -0.0387, -0.0096],\n",
       "                        [-0.0136, -0.0092, -0.0406]],\n",
       "              \n",
       "                       [[-0.0011,  0.0344, -0.0036],\n",
       "                        [ 0.0225,  0.0270, -0.0039],\n",
       "                        [-0.0058,  0.0119,  0.0119]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0129, -0.0167,  0.0088],\n",
       "                        [ 0.0135, -0.0138, -0.0164],\n",
       "                        [-0.0210, -0.0039, -0.0276]],\n",
       "              \n",
       "                       [[-0.0216,  0.0018, -0.0294],\n",
       "                        [-0.0128, -0.0219, -0.0112],\n",
       "                        [-0.0105,  0.0025, -0.0124]],\n",
       "              \n",
       "                       [[-0.0064,  0.0015,  0.0101],\n",
       "                        [ 0.0272, -0.0144,  0.0135],\n",
       "                        [ 0.0059, -0.0305,  0.0360]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0192, -0.0136, -0.0051],\n",
       "                        [ 0.0017, -0.0247,  0.0292],\n",
       "                        [-0.0306, -0.0181,  0.0120]],\n",
       "              \n",
       "                       [[ 0.0306, -0.0302, -0.0340],\n",
       "                        [-0.0355, -0.0251, -0.0028],\n",
       "                        [-0.0156, -0.0136,  0.0091]],\n",
       "              \n",
       "                       [[ 0.0070, -0.0203,  0.0115],\n",
       "                        [-0.0581,  0.0273,  0.0199],\n",
       "                        [-0.0211, -0.0101,  0.0155]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0142, -0.0087, -0.0057],\n",
       "                        [-0.0058,  0.0188, -0.0025],\n",
       "                        [-0.0027, -0.0104,  0.0008]],\n",
       "              \n",
       "                       [[-0.0044,  0.0034, -0.0199],\n",
       "                        [ 0.0022, -0.0082,  0.0010],\n",
       "                        [ 0.0028, -0.0155, -0.0227]],\n",
       "              \n",
       "                       [[ 0.0286, -0.0143, -0.0273],\n",
       "                        [-0.0204, -0.0253, -0.0136],\n",
       "                        [ 0.0177,  0.0193, -0.0200]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0085,  0.0059,  0.0104],\n",
       "                        [ 0.0029, -0.0080, -0.0226],\n",
       "                        [ 0.0231,  0.0065,  0.0241]],\n",
       "              \n",
       "                       [[-0.0274, -0.0296,  0.0028],\n",
       "                        [ 0.0052,  0.0042, -0.0271],\n",
       "                        [ 0.0178, -0.0112,  0.0305]],\n",
       "              \n",
       "                       [[ 0.0023,  0.0012,  0.0616],\n",
       "                        [-0.0015,  0.0244, -0.0263],\n",
       "                        [ 0.0027,  0.0005,  0.0142]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0022, -0.0026,  0.0254],\n",
       "                        [-0.0198, -0.0151,  0.0352],\n",
       "                        [ 0.0428,  0.0116, -0.0065]],\n",
       "              \n",
       "                       [[ 0.0047, -0.0217, -0.0037],\n",
       "                        [ 0.0137, -0.0018, -0.0075],\n",
       "                        [ 0.0169,  0.0037, -0.0047]],\n",
       "              \n",
       "                       [[ 0.0326, -0.0328, -0.0110],\n",
       "                        [ 0.0169,  0.0175, -0.0101],\n",
       "                        [ 0.0045, -0.0073, -0.0143]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0382,  0.0015, -0.0430],\n",
       "                        [-0.0303, -0.0220,  0.0036],\n",
       "                        [ 0.0265, -0.0143, -0.0224]],\n",
       "              \n",
       "                       [[ 0.0071, -0.0337, -0.0449],\n",
       "                        [ 0.0085, -0.0024,  0.0182],\n",
       "                        [-0.0164,  0.0343, -0.0236]],\n",
       "              \n",
       "                       [[ 0.0042, -0.0135, -0.0146],\n",
       "                        [-0.0151,  0.0112,  0.0080],\n",
       "                        [ 0.0253, -0.0202, -0.0093]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0025,  0.0096,  0.0044],\n",
       "                        [ 0.0152,  0.0116,  0.0000],\n",
       "                        [-0.0205,  0.0155,  0.0046]],\n",
       "              \n",
       "                       [[ 0.0109,  0.0270, -0.0140],\n",
       "                        [-0.0070, -0.0161,  0.0153],\n",
       "                        [ 0.0027,  0.0114, -0.0062]],\n",
       "              \n",
       "                       [[-0.0239,  0.0155, -0.0019],\n",
       "                        [-0.0024, -0.0107,  0.0042],\n",
       "                        [ 0.0233, -0.0326,  0.0043]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0136,  0.0031,  0.0072],\n",
       "                        [-0.0065, -0.0261,  0.0464],\n",
       "                        [ 0.0209,  0.0004, -0.0004]],\n",
       "              \n",
       "                       [[ 0.0118,  0.0184,  0.0225],\n",
       "                        [-0.0171,  0.0004, -0.0163],\n",
       "                        [-0.0206, -0.0179, -0.0315]],\n",
       "              \n",
       "                       [[ 0.0010,  0.0353, -0.0056],\n",
       "                        [ 0.0138,  0.0304, -0.0119],\n",
       "                        [ 0.0140,  0.0137,  0.0027]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0216, -0.0025, -0.0103],\n",
       "                        [-0.0360, -0.0020,  0.0117],\n",
       "                        [-0.0490,  0.0228, -0.0391]],\n",
       "              \n",
       "                       [[-0.0106, -0.0018, -0.0251],\n",
       "                        [-0.0412, -0.0227, -0.0091],\n",
       "                        [-0.0077, -0.0035, -0.0054]],\n",
       "              \n",
       "                       [[ 0.0182,  0.0247, -0.0394],\n",
       "                        [-0.0005,  0.0445,  0.0164],\n",
       "                        [-0.0186,  0.0062, -0.0003]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0271, -0.0008,  0.0494],\n",
       "                        [ 0.0070, -0.0374,  0.0466],\n",
       "                        [-0.0013, -0.0058,  0.0097]],\n",
       "              \n",
       "                       [[ 0.0040,  0.0050, -0.0010],\n",
       "                        [ 0.0083,  0.0135, -0.0111],\n",
       "                        [ 0.0079,  0.0131, -0.0080]],\n",
       "              \n",
       "                       [[ 0.0003, -0.0051, -0.0012],\n",
       "                        [-0.0255, -0.0014, -0.0099],\n",
       "                        [-0.0225,  0.0211,  0.0159]]]])),\n",
       "             ('convs.4.bias',\n",
       "              tensor([-2.1558e-07,  5.0547e-07, -3.0809e-06,  2.5422e-06, -3.6671e-07,\n",
       "                       1.7046e-06,  7.0660e-07, -2.6293e-06,  4.2762e-06,  1.2201e-06,\n",
       "                      -1.5170e-06,  3.9054e-06, -1.9436e-06,  2.6917e-06,  2.8343e-06,\n",
       "                       3.0539e-06, -2.6053e-06,  1.6199e-06, -8.8726e-07, -1.4841e-06,\n",
       "                      -3.4354e-06, -1.7908e-06,  1.4434e-06, -3.3710e-06,  5.1284e-06,\n",
       "                       1.3826e-06, -6.3054e-07, -3.1001e-07,  2.9465e-06,  2.7758e-06,\n",
       "                       2.4217e-06, -4.2681e-07, -3.0842e-06,  3.7477e-06, -1.1950e-07,\n",
       "                      -1.8138e-06,  4.4927e-06,  1.9375e-06,  9.9561e-07, -4.1702e-06,\n",
       "                       2.1350e-06,  2.6190e-06,  2.9428e-06,  6.3348e-07, -3.7789e-06,\n",
       "                       5.5434e-07, -2.2801e-06,  3.3993e-06,  2.9997e-06,  7.4293e-07,\n",
       "                      -1.2133e-06,  3.0276e-06,  3.1227e-06, -2.2631e-07,  1.8991e-06,\n",
       "                      -8.4299e-07,  5.0813e-08, -2.7826e-06,  2.5784e-06, -1.4138e-06,\n",
       "                       4.8614e-06, -2.3979e-06,  2.4256e-06, -3.2688e-06, -8.0430e-08,\n",
       "                       7.1472e-07,  3.9001e-06,  3.8051e-06, -1.3717e-06,  1.3371e-06,\n",
       "                       2.9164e-06,  2.1703e-07,  6.8091e-07, -1.3542e-06, -4.3393e-07,\n",
       "                      -1.9653e-06,  1.7465e-07,  2.0874e-06, -1.3111e-06,  3.0076e-06,\n",
       "                      -2.8681e-06, -6.7589e-07,  2.8916e-08,  1.5994e-06,  9.6648e-07,\n",
       "                      -2.4923e-07,  7.6849e-07,  1.3466e-06,  4.3336e-06,  1.5439e-06,\n",
       "                       1.7042e-06, -3.4041e-06, -2.7117e-06, -2.0807e-06, -3.7382e-06,\n",
       "                      -2.1539e-06, -2.9319e-06, -1.7782e-06, -2.1471e-06, -2.0061e-07,\n",
       "                       7.0015e-07, -3.9176e-06, -6.0727e-07,  2.6971e-07, -5.3934e-07,\n",
       "                      -3.1829e-06, -2.4136e-07,  6.8786e-07,  4.3243e-06,  8.3955e-07,\n",
       "                       1.4135e-06, -3.5696e-07,  7.6427e-07, -1.0341e-06,  6.3168e-08,\n",
       "                      -3.0101e-06, -1.3163e-06,  8.9849e-07, -1.2875e-06, -2.2334e-10,\n",
       "                      -1.9603e-06,  1.5117e-06,  1.9349e-06, -1.4264e-06, -2.2886e-06,\n",
       "                      -5.3511e-07, -3.1277e-06,  3.4478e-06])),\n",
       "             ('convs.7.weight', tensor([[[[-0.0080,  0.0079, -0.0150],\n",
       "                        [-0.0365,  0.0403, -0.0040],\n",
       "                        [ 0.0101,  0.0150,  0.0092]],\n",
       "              \n",
       "                       [[-0.0327, -0.0051, -0.0103],\n",
       "                        [-0.0245,  0.0150, -0.0114],\n",
       "                        [-0.0123,  0.0028, -0.0049]],\n",
       "              \n",
       "                       [[ 0.0234, -0.0286, -0.0164],\n",
       "                        [-0.0053, -0.0032,  0.0210],\n",
       "                        [-0.0376, -0.0379,  0.0358]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0030, -0.0151,  0.0065],\n",
       "                        [ 0.0278, -0.0031,  0.0668],\n",
       "                        [ 0.0238, -0.0061, -0.0056]],\n",
       "              \n",
       "                       [[ 0.0020,  0.0002,  0.0052],\n",
       "                        [-0.0009, -0.0330, -0.0018],\n",
       "                        [-0.0059, -0.0147,  0.0074]],\n",
       "              \n",
       "                       [[-0.0072, -0.0141,  0.0118],\n",
       "                        [ 0.0450, -0.0323, -0.0057],\n",
       "                        [-0.0140,  0.0366, -0.0008]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0156,  0.0022, -0.0042],\n",
       "                        [-0.0228, -0.0282,  0.0061],\n",
       "                        [ 0.0167,  0.0069,  0.0059]],\n",
       "              \n",
       "                       [[ 0.0069, -0.0112,  0.0283],\n",
       "                        [ 0.0190,  0.0220,  0.0103],\n",
       "                        [ 0.0206, -0.0018, -0.0067]],\n",
       "              \n",
       "                       [[ 0.0211, -0.0115, -0.0212],\n",
       "                        [ 0.0103,  0.0482,  0.0112],\n",
       "                        [ 0.0006,  0.0142,  0.0064]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0327,  0.0393, -0.0145],\n",
       "                        [-0.0427, -0.0523, -0.0090],\n",
       "                        [ 0.0348,  0.0016,  0.0172]],\n",
       "              \n",
       "                       [[-0.0348,  0.0007,  0.0188],\n",
       "                        [-0.0067, -0.0174, -0.0100],\n",
       "                        [ 0.0110,  0.0125, -0.0223]],\n",
       "              \n",
       "                       [[ 0.0334,  0.0091,  0.0077],\n",
       "                        [-0.0186, -0.0209, -0.0202],\n",
       "                        [-0.0345,  0.0111,  0.0024]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0161,  0.0041,  0.0027],\n",
       "                        [ 0.0053,  0.0184,  0.0381],\n",
       "                        [ 0.0306,  0.0092, -0.0086]],\n",
       "              \n",
       "                       [[ 0.0005,  0.0298,  0.0069],\n",
       "                        [-0.0158,  0.0204, -0.0086],\n",
       "                        [ 0.0002,  0.0042, -0.0175]],\n",
       "              \n",
       "                       [[-0.0157, -0.0049,  0.0380],\n",
       "                        [-0.0174,  0.0435,  0.0099],\n",
       "                        [ 0.0321,  0.0183,  0.0228]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0289, -0.0159,  0.0067],\n",
       "                        [-0.0259,  0.0034, -0.0042],\n",
       "                        [ 0.0039, -0.0241,  0.0169]],\n",
       "              \n",
       "                       [[ 0.0155,  0.0130, -0.0228],\n",
       "                        [ 0.0083, -0.0422, -0.0130],\n",
       "                        [-0.0003, -0.0360,  0.0133]],\n",
       "              \n",
       "                       [[-0.0051, -0.0177, -0.0166],\n",
       "                        [-0.0498, -0.0205, -0.0009],\n",
       "                        [ 0.0045, -0.0075,  0.0101]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0003, -0.0204,  0.0310],\n",
       "                        [-0.0285, -0.0245, -0.0084],\n",
       "                        [-0.0009,  0.0120,  0.0227]],\n",
       "              \n",
       "                       [[ 0.0060, -0.0172,  0.0101],\n",
       "                        [-0.0123,  0.0395,  0.0130],\n",
       "                        [-0.0005, -0.0471, -0.0136]],\n",
       "              \n",
       "                       [[-0.0112,  0.0311, -0.0054],\n",
       "                        [-0.0082, -0.0292,  0.0030],\n",
       "                        [ 0.0031,  0.0050,  0.0177]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0146,  0.0164, -0.0246],\n",
       "                        [ 0.0039, -0.0034,  0.0311],\n",
       "                        [-0.0271, -0.0279, -0.0001]],\n",
       "              \n",
       "                       [[ 0.0119,  0.0062, -0.0170],\n",
       "                        [ 0.0029, -0.0123, -0.0101],\n",
       "                        [ 0.0139, -0.0076,  0.0215]],\n",
       "              \n",
       "                       [[-0.0035, -0.0124,  0.0035],\n",
       "                        [ 0.0253,  0.0058, -0.0048],\n",
       "                        [-0.0122,  0.0233,  0.0103]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0125,  0.0087,  0.0229],\n",
       "                        [ 0.0069, -0.0395, -0.0110],\n",
       "                        [ 0.0265,  0.0046, -0.0152]],\n",
       "              \n",
       "                       [[ 0.0284, -0.0096,  0.0104],\n",
       "                        [ 0.0020, -0.0270,  0.0171],\n",
       "                        [-0.0360,  0.0178,  0.0144]],\n",
       "              \n",
       "                       [[ 0.0044,  0.0050,  0.0240],\n",
       "                        [ 0.0027, -0.0275,  0.0166],\n",
       "                        [-0.0036,  0.0235,  0.0184]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0108, -0.0107, -0.0131],\n",
       "                        [ 0.0002, -0.0154,  0.0356],\n",
       "                        [-0.0524, -0.0070, -0.0261]],\n",
       "              \n",
       "                       [[-0.0150, -0.0041, -0.0344],\n",
       "                        [ 0.0079,  0.0246,  0.0223],\n",
       "                        [ 0.0075, -0.0051, -0.0278]],\n",
       "              \n",
       "                       [[-0.0245, -0.0326,  0.0070],\n",
       "                        [-0.0394, -0.0125,  0.0231],\n",
       "                        [ 0.0233, -0.0064,  0.0032]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0154, -0.0055, -0.0198],\n",
       "                        [ 0.0097, -0.0056,  0.0203],\n",
       "                        [ 0.0106, -0.0113, -0.0007]],\n",
       "              \n",
       "                       [[-0.0269,  0.0040,  0.0254],\n",
       "                        [-0.0089, -0.0680, -0.0101],\n",
       "                        [-0.0049, -0.0190, -0.0119]],\n",
       "              \n",
       "                       [[-0.0044,  0.0019, -0.0057],\n",
       "                        [ 0.0120, -0.0299,  0.0378],\n",
       "                        [-0.0167, -0.0198, -0.0038]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0001,  0.0154,  0.0094],\n",
       "                        [-0.0314,  0.0246, -0.0238],\n",
       "                        [ 0.0140,  0.0225, -0.0161]],\n",
       "              \n",
       "                       [[-0.0013, -0.0120,  0.0057],\n",
       "                        [ 0.0132, -0.0255,  0.0052],\n",
       "                        [-0.0091,  0.0457, -0.0066]],\n",
       "              \n",
       "                       [[ 0.0269,  0.0252, -0.0148],\n",
       "                        [ 0.0016,  0.0166,  0.0337],\n",
       "                        [-0.0177, -0.0150,  0.0022]]]])),\n",
       "             ('convs.7.bias',\n",
       "              tensor([-8.1496e-06,  8.5424e-06, -2.7139e-06,  5.5457e-06,  7.7608e-06,\n",
       "                       8.0422e-06,  7.9849e-06, -6.2992e-06, -7.2384e-06,  8.0319e-06,\n",
       "                       7.0029e-06, -9.2251e-07,  2.9395e-06,  7.6478e-06, -1.8866e-06,\n",
       "                       7.9430e-06, -8.2183e-06,  6.8630e-06,  8.4052e-06,  6.3803e-06,\n",
       "                      -8.5259e-06, -7.5991e-06,  7.3375e-06,  8.2437e-06,  6.1347e-06,\n",
       "                      -8.0961e-06,  1.5660e-06, -6.1422e-06, -8.3126e-06,  8.2914e-06,\n",
       "                      -8.0769e-06, -2.9600e-06,  8.0298e-06, -7.3992e-06, -9.5499e-08,\n",
       "                      -4.4008e-06,  6.4550e-06, -7.4097e-06,  8.0625e-06, -7.4677e-06,\n",
       "                       7.5563e-06,  5.2469e-06, -5.2867e-06, -1.0537e-06,  7.3095e-06,\n",
       "                       7.2337e-06, -8.1086e-06, -4.0116e-06,  7.5933e-06,  6.8076e-06,\n",
       "                      -7.7901e-06,  7.7227e-06,  5.2813e-06,  1.1897e-06, -5.2696e-06,\n",
       "                       7.6225e-06, -4.5871e-06,  7.4051e-06, -6.6567e-06,  8.2516e-06,\n",
       "                      -7.5749e-06, -5.9344e-06, -8.0039e-06, -7.7132e-06,  7.6836e-06,\n",
       "                      -8.1621e-06,  7.8220e-06, -6.8833e-06, -8.0178e-06, -6.3355e-06,\n",
       "                      -7.4094e-06, -7.4225e-06, -6.2861e-06, -8.4676e-06, -8.2706e-06,\n",
       "                       7.6849e-06,  7.7287e-06, -1.5582e-06, -7.4445e-06,  8.0872e-06,\n",
       "                       3.8488e-06, -7.2211e-07, -7.8951e-06,  7.3265e-06, -8.0697e-06,\n",
       "                      -8.2809e-06,  8.1732e-06,  6.4433e-06, -2.9209e-06, -2.2141e-06,\n",
       "                       8.1928e-06,  7.2440e-06,  7.0023e-06,  8.5201e-06,  2.0291e-06,\n",
       "                       6.4106e-06,  8.6138e-06, -8.2497e-06, -8.0393e-06,  8.2599e-06,\n",
       "                      -6.9550e-06, -2.4994e-06, -8.4000e-06, -5.7939e-06,  8.1676e-06,\n",
       "                      -3.9829e-06,  6.3466e-06, -4.2186e-06,  7.1199e-06,  7.0427e-06,\n",
       "                      -3.0841e-06, -8.3765e-06, -1.5942e-06, -8.1827e-06,  7.9554e-06,\n",
       "                       8.2558e-06,  8.7473e-06, -8.2242e-06,  7.4304e-06, -4.4476e-06,\n",
       "                       5.0322e-06, -8.4888e-06, -7.5083e-06,  7.4188e-06,  8.2183e-06,\n",
       "                       2.1719e-06, -8.1957e-06, -8.1822e-06])),\n",
       "             ('convs.9.weight', tensor([[[[-0.0125, -0.0279,  0.0181],\n",
       "                        [ 0.0012,  0.0171,  0.0435],\n",
       "                        [-0.0258, -0.0069, -0.0225]],\n",
       "              \n",
       "                       [[ 0.0151, -0.0416, -0.0067],\n",
       "                        [ 0.0028,  0.0171,  0.0252],\n",
       "                        [ 0.0269, -0.0588,  0.0047]],\n",
       "              \n",
       "                       [[-0.0045,  0.0099, -0.0033],\n",
       "                        [ 0.0287,  0.0091, -0.0095],\n",
       "                        [-0.0163,  0.0206, -0.0034]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0063,  0.0216,  0.0162],\n",
       "                        [ 0.0145, -0.0040, -0.0127],\n",
       "                        [ 0.0287, -0.0068, -0.0021]],\n",
       "              \n",
       "                       [[-0.0092, -0.0253,  0.0065],\n",
       "                        [ 0.0029, -0.0268,  0.0316],\n",
       "                        [-0.0070,  0.0042,  0.0348]],\n",
       "              \n",
       "                       [[-0.0051, -0.0322,  0.0178],\n",
       "                        [-0.0092,  0.0137,  0.0117],\n",
       "                        [ 0.0086, -0.0012,  0.0202]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0236, -0.0092, -0.0072],\n",
       "                        [ 0.0137, -0.0013, -0.0563],\n",
       "                        [ 0.0432, -0.0042,  0.0193]],\n",
       "              \n",
       "                       [[-0.0031,  0.0270,  0.0082],\n",
       "                        [-0.0133, -0.0353,  0.0089],\n",
       "                        [ 0.0001,  0.0046,  0.0091]],\n",
       "              \n",
       "                       [[ 0.0010,  0.0039,  0.0296],\n",
       "                        [-0.0241, -0.0372,  0.0113],\n",
       "                        [ 0.0183,  0.0122,  0.0057]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0050,  0.0041, -0.0054],\n",
       "                        [ 0.0031,  0.0551,  0.0047],\n",
       "                        [-0.0102,  0.0114, -0.0176]],\n",
       "              \n",
       "                       [[-0.0060, -0.0377, -0.0339],\n",
       "                        [-0.0141,  0.0222,  0.0249],\n",
       "                        [-0.0096, -0.0041,  0.0025]],\n",
       "              \n",
       "                       [[-0.0039,  0.0343, -0.0372],\n",
       "                        [ 0.0119, -0.0249, -0.0016],\n",
       "                        [ 0.0043,  0.0213,  0.0056]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0043,  0.0162,  0.0392],\n",
       "                        [ 0.0160, -0.0196,  0.0208],\n",
       "                        [-0.0034,  0.0247, -0.0017]],\n",
       "              \n",
       "                       [[-0.0028, -0.0228,  0.0161],\n",
       "                        [-0.0210, -0.0068,  0.0336],\n",
       "                        [ 0.0258, -0.0473, -0.0441]],\n",
       "              \n",
       "                       [[-0.0271, -0.0031,  0.0076],\n",
       "                        [ 0.0067, -0.0137, -0.0027],\n",
       "                        [ 0.0242, -0.0009, -0.0163]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0091, -0.0084, -0.0018],\n",
       "                        [ 0.0314,  0.0121,  0.0110],\n",
       "                        [-0.0119, -0.0111,  0.0037]],\n",
       "              \n",
       "                       [[ 0.0174,  0.0207,  0.0059],\n",
       "                        [ 0.0062,  0.0283, -0.0011],\n",
       "                        [ 0.0219,  0.0031,  0.0202]],\n",
       "              \n",
       "                       [[ 0.0220,  0.0144, -0.0167],\n",
       "                        [-0.0016,  0.0119,  0.0065],\n",
       "                        [ 0.0141, -0.0054, -0.0312]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0222, -0.0055, -0.0004],\n",
       "                        [ 0.0170,  0.0412, -0.0223],\n",
       "                        [-0.0259, -0.0289, -0.0100]],\n",
       "              \n",
       "                       [[ 0.0003,  0.0013,  0.0087],\n",
       "                        [-0.0099,  0.0155, -0.0274],\n",
       "                        [-0.0022,  0.0285,  0.0014]],\n",
       "              \n",
       "                       [[ 0.0079, -0.0607, -0.0149],\n",
       "                        [-0.0189,  0.0072,  0.0178],\n",
       "                        [-0.0270, -0.0116,  0.0398]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0019, -0.0109, -0.0069],\n",
       "                        [ 0.0131, -0.0012,  0.0294],\n",
       "                        [-0.0257, -0.0051,  0.0041]],\n",
       "              \n",
       "                       [[-0.0090,  0.0017, -0.0188],\n",
       "                        [-0.0120, -0.0123, -0.0255],\n",
       "                        [ 0.0334, -0.0081,  0.0140]],\n",
       "              \n",
       "                       [[ 0.0068,  0.0034, -0.0117],\n",
       "                        [-0.0034, -0.0201, -0.0045],\n",
       "                        [ 0.0034,  0.0104, -0.0176]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0267,  0.0328, -0.0035],\n",
       "                        [-0.0220, -0.0050, -0.0116],\n",
       "                        [-0.0183, -0.0078, -0.0230]],\n",
       "              \n",
       "                       [[-0.0181,  0.0304, -0.0028],\n",
       "                        [-0.0178, -0.0089, -0.0323],\n",
       "                        [ 0.0086, -0.0112,  0.0111]],\n",
       "              \n",
       "                       [[-0.0316,  0.0437, -0.0103],\n",
       "                        [ 0.0035, -0.0268, -0.0266],\n",
       "                        [ 0.0052, -0.0057, -0.0050]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0158,  0.0322,  0.0023],\n",
       "                        [ 0.0165, -0.0031, -0.0152],\n",
       "                        [-0.0055,  0.0062, -0.0086]],\n",
       "              \n",
       "                       [[ 0.0066, -0.0057,  0.0124],\n",
       "                        [ 0.0285, -0.0224, -0.0018],\n",
       "                        [-0.0162,  0.0166,  0.0172]],\n",
       "              \n",
       "                       [[ 0.0312, -0.0041,  0.0033],\n",
       "                        [ 0.0035, -0.0007, -0.0006],\n",
       "                        [ 0.0099, -0.0041,  0.0208]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0099, -0.0179,  0.0143],\n",
       "                        [ 0.0126, -0.0062,  0.0165],\n",
       "                        [-0.0090, -0.0164,  0.0133]],\n",
       "              \n",
       "                       [[ 0.0054, -0.0064,  0.0053],\n",
       "                        [-0.0049, -0.0194,  0.0234],\n",
       "                        [ 0.0012, -0.0051,  0.0163]],\n",
       "              \n",
       "                       [[-0.0369,  0.0165, -0.0069],\n",
       "                        [-0.0023,  0.0287, -0.0238],\n",
       "                        [ 0.0271,  0.0115,  0.0045]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0050, -0.0180,  0.0011],\n",
       "                        [-0.0295, -0.0008, -0.0067],\n",
       "                        [ 0.0028,  0.0034, -0.0106]],\n",
       "              \n",
       "                       [[-0.0171, -0.0040,  0.0286],\n",
       "                        [ 0.0091,  0.0111, -0.0050],\n",
       "                        [-0.0031, -0.0016, -0.0286]],\n",
       "              \n",
       "                       [[-0.0083, -0.0138, -0.0482],\n",
       "                        [ 0.0280, -0.0045,  0.0224],\n",
       "                        [ 0.0319, -0.0239, -0.0069]]]])),\n",
       "             ('convs.9.bias',\n",
       "              tensor([ 1.6285e-07,  4.5177e-08, -6.1156e-08, -8.7620e-09,  5.6154e-08,\n",
       "                      -2.3578e-08, -2.3562e-08,  4.7451e-08,  4.6846e-08, -5.3163e-08,\n",
       "                      -7.7155e-09, -1.4567e-07,  2.8744e-08,  1.6451e-08, -2.2666e-09,\n",
       "                       8.9351e-08, -1.8727e-08,  2.4025e-08, -2.4625e-08, -2.8730e-08,\n",
       "                      -4.6081e-08, -5.3602e-08, -2.5007e-08, -4.2762e-08, -7.7828e-08,\n",
       "                       4.8983e-08,  2.8777e-08, -3.8347e-08,  1.3824e-08, -2.6604e-08,\n",
       "                      -3.9309e-08, -2.8515e-08, -4.1889e-08, -9.1137e-09, -1.2038e-08,\n",
       "                       1.9527e-08,  2.6577e-08,  3.5725e-08, -4.3048e-08, -8.8434e-08,\n",
       "                      -2.7085e-08,  4.2114e-08,  3.7578e-08, -7.2770e-08, -5.4607e-09,\n",
       "                      -4.7954e-08,  1.1701e-07,  1.2306e-08,  2.2008e-08,  1.0765e-08,\n",
       "                      -1.6824e-08, -1.3077e-08, -2.2061e-08,  5.8929e-08, -3.9869e-08,\n",
       "                      -7.5641e-08,  7.5731e-08, -1.0153e-09, -6.4761e-09, -2.5316e-08,\n",
       "                       6.9344e-08, -2.5271e-08,  2.0590e-08,  8.9310e-08,  8.2143e-08,\n",
       "                      -2.9486e-08, -2.1555e-08, -2.9629e-08,  2.6732e-08, -1.6266e-07,\n",
       "                      -2.8281e-08,  6.8099e-08, -1.8002e-08, -9.2103e-09, -1.8355e-07,\n",
       "                       5.2172e-08,  1.1389e-07,  1.6583e-08,  1.0316e-07, -6.8929e-08,\n",
       "                      -1.3588e-07,  9.4044e-09, -7.1874e-08,  4.0047e-08,  3.2724e-08,\n",
       "                      -5.5329e-09,  1.8927e-08,  5.7693e-08, -6.8714e-08, -5.3976e-08,\n",
       "                      -3.0207e-09, -3.5212e-08,  1.0222e-08,  1.8437e-08,  2.4140e-08,\n",
       "                       5.7455e-08, -4.2010e-09,  1.3985e-08, -7.3998e-09, -1.8050e-08,\n",
       "                       6.5749e-08,  1.5478e-07, -7.4330e-08, -1.5642e-08,  6.3880e-08,\n",
       "                       5.5307e-08, -3.0171e-08,  2.6066e-08,  1.8276e-08, -1.5355e-07,\n",
       "                       5.8547e-08, -5.3726e-08, -2.8341e-08,  3.6455e-08,  2.0340e-08,\n",
       "                       9.2062e-08, -1.6202e-08,  2.3784e-08, -2.1051e-08, -7.2763e-08,\n",
       "                       1.3285e-08,  4.0581e-08, -6.0622e-09,  1.3109e-07, -6.2438e-08,\n",
       "                       8.7038e-08, -1.2914e-08, -4.8835e-09,  4.1978e-08, -1.2849e-07,\n",
       "                       2.1944e-09,  1.0979e-07,  2.4350e-08,  7.6949e-08, -2.3501e-08,\n",
       "                      -8.1881e-08,  1.2391e-08, -2.1445e-08,  2.3845e-08,  1.3419e-10,\n",
       "                      -2.9085e-08,  1.6996e-08,  7.7638e-08,  2.5347e-08, -4.2871e-09,\n",
       "                      -1.2987e-07, -7.6741e-08, -2.4298e-08, -1.3367e-08, -2.9163e-08,\n",
       "                      -1.1575e-07, -1.6538e-07,  7.0408e-09,  3.2424e-08, -2.5856e-09,\n",
       "                       1.0231e-07, -1.3938e-07,  3.0308e-08,  5.1569e-08, -1.2354e-08,\n",
       "                       1.5954e-08,  4.3500e-08,  3.0281e-08, -4.7420e-08, -1.5542e-08,\n",
       "                       1.6522e-07, -9.7755e-09,  6.7504e-08, -5.4802e-08,  1.3926e-08,\n",
       "                       9.9382e-10, -2.4113e-08,  2.2678e-08, -1.2417e-08, -1.4367e-08,\n",
       "                      -7.2830e-08,  3.5069e-08, -1.5268e-08,  8.2086e-08,  1.2599e-08,\n",
       "                       3.4777e-09,  1.6187e-08, -2.6057e-08,  4.1766e-08,  6.9701e-08,\n",
       "                       1.5269e-08, -4.2007e-08, -1.2505e-08,  9.8354e-08,  1.9671e-10,\n",
       "                       3.3617e-08,  7.2482e-09, -9.8270e-08, -1.1806e-08,  1.0148e-07,\n",
       "                       1.3908e-09,  5.2229e-08, -7.4027e-08,  6.7610e-08,  3.9392e-08,\n",
       "                       1.9901e-09,  3.6467e-08, -5.2380e-08,  9.9696e-09, -4.8153e-09,\n",
       "                      -6.3823e-08, -1.1386e-07, -5.4355e-08, -6.7576e-09,  1.0632e-07,\n",
       "                       1.3018e-08,  3.3587e-08, -6.9933e-08,  5.6011e-08, -3.6785e-08,\n",
       "                      -7.7408e-08, -3.4832e-08,  6.9161e-08, -9.0711e-09, -2.5960e-09,\n",
       "                       6.8548e-08,  4.7393e-09, -4.8826e-09, -3.8546e-08,  2.4574e-08,\n",
       "                      -4.1191e-08, -4.8630e-09, -1.1376e-08, -3.9459e-09,  2.2447e-08,\n",
       "                      -2.9253e-08, -1.1842e-07,  1.2324e-07,  7.7647e-08, -2.2065e-08,\n",
       "                      -9.6182e-08,  8.4721e-09,  2.4295e-08,  3.6045e-08, -4.0981e-08,\n",
       "                      -4.6799e-08, -8.1425e-08,  1.6059e-08,  5.9819e-08,  1.2953e-08,\n",
       "                      -1.0582e-07, -3.6165e-08,  1.9332e-07, -4.8013e-08, -7.0331e-08,\n",
       "                      -2.9057e-09,  1.0932e-08,  1.8076e-08,  1.3075e-07, -1.8113e-07,\n",
       "                       5.8805e-09])),\n",
       "             ('convs.12.weight', tensor([[[[ 0.0027,  0.0045,  0.0125],\n",
       "                        [-0.0023, -0.0146, -0.0298],\n",
       "                        [ 0.0289,  0.0111, -0.0132]],\n",
       "              \n",
       "                       [[ 0.0264, -0.0155,  0.0171],\n",
       "                        [-0.0054,  0.0296,  0.0229],\n",
       "                        [-0.0022,  0.0103, -0.0235]],\n",
       "              \n",
       "                       [[ 0.0169,  0.0010,  0.0287],\n",
       "                        [-0.0464,  0.0204, -0.0106],\n",
       "                        [-0.0158,  0.0098, -0.0007]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0131,  0.0183, -0.0121],\n",
       "                        [-0.0133,  0.0541,  0.0015],\n",
       "                        [ 0.0214,  0.0136,  0.0088]],\n",
       "              \n",
       "                       [[-0.0347, -0.0448,  0.0093],\n",
       "                        [-0.0176, -0.0035,  0.0213],\n",
       "                        [-0.0085,  0.0046, -0.0170]],\n",
       "              \n",
       "                       [[-0.0125,  0.0199,  0.0028],\n",
       "                        [ 0.0029, -0.0163,  0.0024],\n",
       "                        [ 0.0337, -0.0249, -0.0110]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0149, -0.0404,  0.0367],\n",
       "                        [-0.0148,  0.0292,  0.0173],\n",
       "                        [ 0.0029,  0.0331,  0.0112]],\n",
       "              \n",
       "                       [[ 0.0120,  0.0135,  0.0387],\n",
       "                        [-0.0140,  0.0050, -0.0026],\n",
       "                        [ 0.0144, -0.0074,  0.0108]],\n",
       "              \n",
       "                       [[ 0.0239, -0.0227,  0.0103],\n",
       "                        [ 0.0010,  0.0018,  0.0157],\n",
       "                        [ 0.0183,  0.0030,  0.0072]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0347, -0.0066, -0.0267],\n",
       "                        [-0.0401,  0.0008, -0.0147],\n",
       "                        [ 0.0061, -0.0052,  0.0060]],\n",
       "              \n",
       "                       [[ 0.0018, -0.0147, -0.0212],\n",
       "                        [-0.0078, -0.0136,  0.0046],\n",
       "                        [ 0.0427,  0.0071, -0.0128]],\n",
       "              \n",
       "                       [[-0.0116, -0.0386,  0.0240],\n",
       "                        [ 0.0098, -0.0048, -0.0278],\n",
       "                        [-0.0053,  0.0097,  0.0154]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0060,  0.0209, -0.0044],\n",
       "                        [ 0.0128, -0.0282,  0.0176],\n",
       "                        [-0.0063,  0.0202, -0.0130]],\n",
       "              \n",
       "                       [[-0.0229, -0.0250,  0.0025],\n",
       "                        [ 0.0154,  0.0145,  0.0151],\n",
       "                        [-0.0237,  0.0033,  0.0069]],\n",
       "              \n",
       "                       [[-0.0283,  0.0212, -0.0345],\n",
       "                        [-0.0012,  0.0186, -0.0058],\n",
       "                        [-0.0107,  0.0064,  0.0177]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0108,  0.0269, -0.0089],\n",
       "                        [-0.0060,  0.0007, -0.0064],\n",
       "                        [ 0.0048,  0.0087,  0.0149]],\n",
       "              \n",
       "                       [[-0.0125,  0.0220, -0.0143],\n",
       "                        [-0.0089,  0.0012,  0.0126],\n",
       "                        [-0.0388, -0.0262, -0.0101]],\n",
       "              \n",
       "                       [[-0.0009, -0.0264,  0.0111],\n",
       "                        [ 0.0143,  0.0240, -0.0071],\n",
       "                        [ 0.0143, -0.0130,  0.0211]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0251,  0.0092, -0.0062],\n",
       "                        [-0.0049,  0.0245, -0.0217],\n",
       "                        [ 0.0180, -0.0145, -0.0119]],\n",
       "              \n",
       "                       [[ 0.0319,  0.0183, -0.0150],\n",
       "                        [-0.0431, -0.0096, -0.0205],\n",
       "                        [ 0.0206,  0.0005, -0.0133]],\n",
       "              \n",
       "                       [[-0.0353, -0.0230,  0.0101],\n",
       "                        [-0.0038, -0.0021,  0.0008],\n",
       "                        [-0.0001, -0.0414, -0.0171]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0426, -0.0016,  0.0280],\n",
       "                        [ 0.0113, -0.0193, -0.0330],\n",
       "                        [-0.0003, -0.0184, -0.0205]],\n",
       "              \n",
       "                       [[-0.0205, -0.0022, -0.0433],\n",
       "                        [-0.0205, -0.0198, -0.0042],\n",
       "                        [-0.0178,  0.0045,  0.0077]],\n",
       "              \n",
       "                       [[-0.0366, -0.0067,  0.0080],\n",
       "                        [-0.0027, -0.0166,  0.0116],\n",
       "                        [ 0.0381,  0.0030,  0.0209]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0457, -0.0148,  0.0162],\n",
       "                        [ 0.0131,  0.0127,  0.0036],\n",
       "                        [-0.0054,  0.0021,  0.0078]],\n",
       "              \n",
       "                       [[ 0.0183,  0.0212, -0.0112],\n",
       "                        [-0.0322,  0.0017,  0.0241],\n",
       "                        [ 0.0090,  0.0157, -0.0223]],\n",
       "              \n",
       "                       [[-0.0097,  0.0120,  0.0096],\n",
       "                        [-0.0128,  0.0085,  0.0117],\n",
       "                        [ 0.0054,  0.0105, -0.0155]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0007,  0.0057,  0.0013],\n",
       "                        [-0.0122,  0.0300,  0.0191],\n",
       "                        [-0.0228,  0.0028,  0.0006]],\n",
       "              \n",
       "                       [[ 0.0152, -0.0085, -0.0008],\n",
       "                        [ 0.0099, -0.0108, -0.0209],\n",
       "                        [ 0.0046, -0.0060,  0.0118]],\n",
       "              \n",
       "                       [[ 0.0030, -0.0171,  0.0105],\n",
       "                        [ 0.0264, -0.0154,  0.0054],\n",
       "                        [ 0.0260, -0.0235, -0.0567]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0357, -0.0099, -0.0167],\n",
       "                        [-0.0196,  0.0188, -0.0128],\n",
       "                        [-0.0014,  0.0189,  0.0272]],\n",
       "              \n",
       "                       [[ 0.0284,  0.0416, -0.0035],\n",
       "                        [ 0.0199, -0.0109,  0.0060],\n",
       "                        [-0.0169,  0.0108, -0.0146]],\n",
       "              \n",
       "                       [[-0.0149,  0.0291,  0.0107],\n",
       "                        [ 0.0084,  0.0082,  0.0147],\n",
       "                        [-0.0115, -0.0219, -0.0053]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0248, -0.0091, -0.0236],\n",
       "                        [-0.0068, -0.0219,  0.0088],\n",
       "                        [ 0.0044, -0.0050,  0.0063]],\n",
       "              \n",
       "                       [[-0.0195,  0.0260,  0.0205],\n",
       "                        [ 0.0217,  0.0122,  0.0010],\n",
       "                        [-0.0354, -0.0240, -0.0106]],\n",
       "              \n",
       "                       [[-0.0282, -0.0446, -0.0208],\n",
       "                        [ 0.0128, -0.0126, -0.0058],\n",
       "                        [ 0.0139, -0.0126,  0.0016]]]])),\n",
       "             ('convs.12.bias',\n",
       "              tensor([-4.6677e-09, -5.8122e-09,  2.1529e-09,  3.5440e-09, -3.3919e-09,\n",
       "                       2.9374e-09,  5.1449e-09,  6.6536e-09, -1.2452e-10, -1.0482e-09,\n",
       "                      -9.0538e-09, -2.8604e-09, -4.7322e-09,  7.8143e-09,  4.4944e-09,\n",
       "                      -6.0616e-09,  5.2802e-08, -1.5651e-09,  1.4405e-09, -5.1023e-09,\n",
       "                       8.2833e-09,  1.5083e-08, -3.6566e-10,  1.1086e-09, -2.1547e-09,\n",
       "                       5.5465e-09, -4.6582e-10,  4.4277e-09, -9.7839e-09, -2.9858e-10,\n",
       "                      -1.7086e-08,  7.0950e-09,  5.2567e-09,  9.1028e-09,  3.2851e-08,\n",
       "                       7.6883e-09,  5.8025e-10, -3.6564e-10,  2.1854e-08,  1.6032e-08,\n",
       "                      -1.2499e-08, -2.0937e-09, -1.2854e-08, -3.5659e-09,  1.0983e-09,\n",
       "                      -1.9979e-08, -7.7245e-10, -8.2054e-10, -1.1815e-09,  5.3791e-09,\n",
       "                      -3.2002e-09, -4.1000e-09, -7.9891e-09,  6.9971e-09, -6.3690e-09,\n",
       "                       2.8860e-09,  9.1612e-10,  1.4259e-09,  4.2698e-09,  5.7925e-09,\n",
       "                      -1.6402e-08, -8.0008e-09,  1.2961e-08,  4.2712e-09,  1.6950e-08,\n",
       "                      -2.2778e-09, -8.2513e-09, -2.7608e-08, -1.5458e-08, -1.0922e-08,\n",
       "                      -2.0888e-09,  3.0297e-09,  3.6910e-09,  2.9940e-09, -2.2424e-08,\n",
       "                       1.9775e-10, -1.0633e-08,  2.2971e-09, -4.4722e-09,  5.2059e-09,\n",
       "                      -5.9394e-09,  7.3990e-09,  1.7668e-08, -3.0290e-08,  3.6443e-09,\n",
       "                      -7.0478e-09,  6.7150e-09,  3.1050e-09, -3.6272e-08,  9.0469e-09,\n",
       "                      -2.6880e-09, -5.1722e-09,  5.4770e-09,  1.4001e-08, -7.1598e-09,\n",
       "                      -8.0973e-09, -4.9770e-09, -1.6161e-09,  7.7491e-09, -1.6013e-08,\n",
       "                      -3.9497e-09, -8.7610e-09, -6.6009e-10, -1.0507e-08,  1.7503e-08,\n",
       "                      -7.0765e-09,  1.3527e-08, -2.3581e-09,  7.2524e-09, -3.8408e-09,\n",
       "                       6.7188e-11,  3.0390e-09, -2.6673e-09,  8.1665e-10, -6.1626e-09,\n",
       "                      -6.7914e-09, -3.7770e-11,  1.4606e-08,  1.7317e-08,  1.6695e-10,\n",
       "                      -1.4102e-08,  5.1650e-09, -4.0108e-10, -1.8969e-09, -2.1794e-08,\n",
       "                      -1.4477e-08, -8.1081e-09,  2.2378e-09, -1.7026e-08,  3.0124e-08,\n",
       "                      -1.5205e-08, -1.0398e-08,  1.8284e-08,  6.5289e-10, -6.4587e-10,\n",
       "                      -1.2903e-08, -3.6501e-09, -4.7156e-09, -4.9607e-09, -7.5462e-09,\n",
       "                       3.0476e-08,  7.5584e-09,  2.0839e-09,  6.1068e-10,  3.1465e-09,\n",
       "                       3.5395e-09, -7.5397e-09, -6.1014e-09, -6.3330e-09, -3.0675e-09,\n",
       "                       4.9029e-09, -5.7710e-09, -3.8765e-09, -1.8083e-09,  1.2306e-09,\n",
       "                      -1.3503e-08, -5.1935e-09,  3.2171e-10,  2.5801e-08,  8.9967e-09,\n",
       "                       6.5419e-09, -5.0878e-09, -2.3876e-08, -5.8591e-09, -2.5838e-09,\n",
       "                       3.7960e-09, -4.2506e-09,  7.0608e-10,  8.2499e-09, -1.3237e-08,\n",
       "                       4.4287e-09, -1.1432e-08,  8.2622e-09, -1.7746e-08, -2.1331e-10,\n",
       "                       8.1931e-09, -6.0496e-08, -2.5704e-09, -2.1936e-08,  1.1014e-08,\n",
       "                      -6.1100e-09, -2.3698e-08, -8.7007e-09,  4.6204e-09,  8.6679e-09,\n",
       "                      -6.8774e-10, -3.1453e-09,  9.7041e-09, -4.3062e-09,  2.8339e-11,\n",
       "                      -1.0539e-08, -1.1616e-08, -1.9338e-08,  1.0074e-09, -3.1877e-09,\n",
       "                      -1.1325e-09, -8.5770e-09,  1.2050e-08, -1.0533e-08,  2.0662e-08,\n",
       "                       3.3421e-09,  1.3713e-08,  3.2330e-09,  1.1141e-08,  8.4816e-09,\n",
       "                      -3.6569e-08, -1.2248e-08, -8.5855e-09,  1.2119e-08,  1.2217e-08,\n",
       "                      -3.5928e-09,  9.8505e-09, -8.6462e-09, -9.4454e-09,  1.5285e-08,\n",
       "                       1.5227e-08, -1.3032e-08,  1.2421e-08, -3.6580e-09, -4.3165e-09,\n",
       "                       9.5360e-10, -1.6465e-10, -6.5489e-09,  4.8508e-10, -7.7701e-10,\n",
       "                       4.7929e-09,  2.9655e-09, -4.8857e-10, -1.3491e-08,  3.7809e-09,\n",
       "                       1.0231e-08, -6.0823e-09, -1.0039e-09, -1.3006e-08, -2.5610e-09,\n",
       "                       3.4901e-08,  2.4600e-08,  2.2244e-09, -1.9028e-08, -1.8995e-09,\n",
       "                       6.3560e-09, -1.0168e-08, -4.2962e-09,  9.9989e-09, -6.1947e-09,\n",
       "                      -7.4901e-10,  2.1633e-09,  5.4723e-09,  1.5979e-08, -1.0837e-08,\n",
       "                       1.8728e-08, -1.3968e-09,  9.4226e-10, -6.3272e-08,  2.5011e-09,\n",
       "                      -4.3899e-09])),\n",
       "             ('convs.15.weight', tensor([[[[-0.0009,  0.0049,  0.0142],\n",
       "                        [-0.0141, -0.0156,  0.0306],\n",
       "                        [ 0.0309,  0.0129,  0.0388]],\n",
       "              \n",
       "                       [[-0.0053,  0.0378, -0.0318],\n",
       "                        [-0.0114,  0.0438,  0.0136],\n",
       "                        [-0.0447, -0.0129, -0.0113]],\n",
       "              \n",
       "                       [[-0.0157,  0.0037,  0.0342],\n",
       "                        [ 0.0128,  0.0046,  0.0008],\n",
       "                        [-0.0299,  0.0292,  0.0110]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0146, -0.0205,  0.0130],\n",
       "                        [ 0.0141,  0.0262,  0.0181],\n",
       "                        [ 0.0293,  0.0379, -0.0059]],\n",
       "              \n",
       "                       [[ 0.0166,  0.0231, -0.0010],\n",
       "                        [ 0.0034, -0.0032, -0.0278],\n",
       "                        [-0.0362, -0.0042, -0.0167]],\n",
       "              \n",
       "                       [[ 0.0089,  0.0114, -0.0181],\n",
       "                        [-0.0250,  0.0612, -0.0241],\n",
       "                        [-0.0121,  0.0155,  0.0066]]]])),\n",
       "             ('convs.15.bias', tensor([-0.0000]))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
