{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from lib import utils, networks, train_history\n",
    "import itertools\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input channel for generator\n",
    "in_ngc=3\n",
    "#output channel for generator\n",
    "out_ngc=3\n",
    "#input channel for discriminator\n",
    "in_ndc=3\n",
    "#output channel for discriminator\n",
    "out_ndc=1\n",
    "batch_size=8\n",
    "ngf=64\n",
    "ndf=16\n",
    "#the number of resnet block layer for generator\n",
    "nb=5\n",
    "#input size\n",
    "input_size=64\n",
    "ng_downsampling=3\n",
    "nd_downsampling=3\n",
    "\n",
    "train_epoch=20\n",
    "#Discriminator learning rate, default=0.0002\n",
    "lrD=0.0001\n",
    "#Generator learning rate, default=0.0002\n",
    "lrG=0.0001\n",
    "#lambda for loss\n",
    "lambdaA=10\n",
    "lambdaB=10\n",
    "lambda_cycle = 1\n",
    "# lambda_idt = 1\n",
    "decay_epoch = 10\n",
    "\n",
    "# wgan number of critics\n",
    "n_critic = 5\n",
    "\n",
    "#beta1 for Adam optimizer\n",
    "beta1=0\n",
    "#beta2 for Adam optimizer\n",
    "beta2=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results path\n",
    "project_result_path='cycleGAN_7'\n",
    "cycle_A_path = os.path.join(project_result_path, 'Cycle_G_A')\n",
    "cycle_B_path = os.path.join(project_result_path, 'Cycle_G_B')\n",
    "if not os.path.isdir(cycle_A_path):\n",
    "    os.makedirs(cycle_A_path)\n",
    "if not os.path.isdir(cycle_B_path):\n",
    "    os.makedirs(cycle_B_path)\n",
    "\n",
    "#data path\n",
    "data_path = 'data'\n",
    "src_data_path= os.path.join(data_path,'src_data_path_new')\n",
    "tgt_data_path= os.path.join(data_path,'tgt_data_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_loader_A = torch.utils.data.DataLoader(datasets.ImageFolder(src_data_path, transform), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "train_loader_B = torch.utils.data.DataLoader(datasets.ImageFolder(tgt_data_path, transform), batch_size=batch_size, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n",
    "G_A = networks.cyclegan_generator1(in_ngc, out_ngc, ngf, nb, ng_downsampling)\n",
    "G_B = networks.cyclegan_generator1(in_ngc, out_ngc, ngf, nb, ng_downsampling)\n",
    "D_A = networks.wgan_discriminator(in_ndc, ndf, input_size, nd_downsampling)\n",
    "D_B = networks.wgan_discriminator(in_ndc, ndf, input_size, nd_downsampling)\n",
    "\n",
    "G_A.to(device)\n",
    "G_B.to(device)\n",
    "D_A.to(device)\n",
    "D_B.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "BCE_loss = nn.BCELoss().to(device)\n",
    "MSE_loss = nn.MSELoss().to(device)\n",
    "L1_loss = nn.L1Loss().to(device)\n",
    "\n",
    "# def D_loss_criterion(D_decision,device,zeros,trick=True):\n",
    "#     if(zeros):\n",
    "#         if(trick):\n",
    "#             return BCE_loss(D_decision, torch.rand(D_decision.size(), device=device)/10.0)\n",
    "#         return BCE_loss(D_decision, torch.zeros(D_decision.size(), device=device))\n",
    "#     else:\n",
    "#         if(trick):\n",
    "#             return BCE_loss(D_decision, 1-torch.rand(D_decision.size(), device=device)/10.0)\n",
    "#         return BCE_loss(D_decision, torch.ones(D_decision.size(), device=device))\n",
    "\n",
    "def D_loss_criterion(D_decision):\n",
    "    return D_decision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optimizer = optim.Adam(itertools.chain(G_A.parameters(), G_B.parameters()), lr=lrG, betas=(beta1, beta2))\n",
    "D_A_optimizer = optim.Adam(D_A.parameters(), lr=lrD, betas=(beta1, beta2))\n",
    "D_B_optimizer = optim.Adam(D_B.parameters(), lr=lrD, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = train_history.train_history(['per_epoch_time',\n",
    "                                          'G_gan_loss',\n",
    "                                          'G_cycle_loss',\n",
    "                                          'D_A_fake_loss',\n",
    "                                          'D_A_real_loss',\n",
    "                                          'D_B_fake_loss',\n",
    "                                          'D_B_real_loss'                                          \n",
    "                                          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_A.load_state_dict(torch.load(os.path.join(project_result_path, 'G_A.pkl')))\n",
    "G_B.load_state_dict(torch.load(os.path.join(project_result_path, 'G_B.pkl')))\n",
    "D_A.load_state_dict(torch.load(os.path.join(project_result_path, 'D_A.pkl')))\n",
    "D_B.load_state_dict(torch.load(os.path.join(project_result_path, 'D_B.pkl')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist.load_train(os.path.join(project_result_path, 'train_hist.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the starting_epoch if needed\n",
    "starting_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    alpha = torch.rand(batch_size, 1)\n",
    "    alpha = alpha.expand(batch_size, real_data.nelement()//batch_size).contiguous()\n",
    "    alpha = alpha.view(batch_size, 3, input_size, input_size)\n",
    "    alpha = alpha.to(device)\n",
    "#     alpha = torch.rand(real_data.size(), device=device)\n",
    "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
    "    interpolates = interpolates.to(device)\n",
    "    interpolates.requires_grad_(True)   \n",
    "\n",
    "    disc_interpolates = netD(interpolates)\n",
    "    gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1) \n",
    "    gradient_penalty = 10* ((1-(gradients+1e-16).norm(2, dim=1)) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start!\n",
      "==> Epoch 1/20\n",
      "1/20 per_epoch_time:114.574,G_gan_loss:107.141,G_cycle_loss:11.692,D_A_fake_loss:2.868,D_A_real_loss:1.532,D_B_fake_loss:7.331,D_B_real_loss:6.784,\n",
      "==> Epoch 2/20\n",
      "2/20 per_epoch_time:115.385,G_gan_loss:102.674,G_cycle_loss:11.399,D_A_fake_loss:0.943,D_A_real_loss:0.655,D_B_fake_loss:9.043,D_B_real_loss:9.586,\n",
      "==> Epoch 3/20\n",
      "3/20 per_epoch_time:115.099,G_gan_loss:216.420,G_cycle_loss:11.460,D_A_fake_loss:2.321,D_A_real_loss:2.596,D_B_fake_loss:18.710,D_B_real_loss:19.651,\n",
      "==> Epoch 4/20\n",
      "4/20 per_epoch_time:115.467,G_gan_loss:423.443,G_cycle_loss:11.397,D_A_fake_loss:11.668,D_A_real_loss:12.427,D_B_fake_loss:29.986,D_B_real_loss:31.840,\n",
      "==> Epoch 5/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2c0110f2917c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtrain_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtrain_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_B\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mG_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mG_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \"\"\"\n\u001b[1;32m    100\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    877\u001b[0m         \"\"\"\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('training start!')\n",
    "start_time = time.time()\n",
    "num_pool = 50\n",
    "fake_A_pool = utils.ImagePool(num_pool)\n",
    "fake_B_pool = utils.ImagePool(num_pool)\n",
    "for epoch in range(train_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    print(\"==> Epoch {}/{}\".format(starting_epoch+epoch + 1, starting_epoch+train_epoch))\n",
    "    if (epoch + 1) > decay_epoch:\n",
    "        D_A_optimizer.param_groups[0]['lr'] -= lrD / 10\n",
    "        D_B_optimizer.param_groups[0]['lr'] -= lrD / 10\n",
    "        G_optimizer.param_groups[0]['lr'] -= lrG / 10\n",
    "    \n",
    "    G_gan_losses = []\n",
    "    G_cycle_losses = []\n",
    "\n",
    "    D_A_real_losses = []\n",
    "    D_A_fake_losses = []\n",
    "    D_B_real_losses = []\n",
    "    D_B_fake_losses = []\n",
    "\n",
    "    \n",
    "    train_G = False\n",
    "    train_D = False\n",
    "    for i, ((real_A,_),(real_B,_)) in enumerate(zip(train_loader_A, train_loader_B)):\n",
    "        G_A.train()\n",
    "        G_B.train()\n",
    "\n",
    "        # input image data\n",
    "        real_A = real_A.to(device)\n",
    "        real_B = real_B.to(device)\n",
    "        if(i%5 == 0):\n",
    "            #fix D parameters\n",
    "            for model in [D_A, D_B]:\n",
    "                for param in model.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "            # Train generator G\n",
    "            # A -> B\n",
    "            fake_B = G_A(real_A)\n",
    "            D_B_fake_decision = D_B(fake_B)\n",
    "    #         G_A_loss = D_loss_criterion(D_B_fake_decision,device,zeros=False,trick=False)\n",
    "            G_A_loss = D_loss_criterion(D_B_fake_decision)  * lambdaA\n",
    "\n",
    "            # identity loss\n",
    "    #         G_A_idt_loss = L1_loss(fake_B, real_A) * lambdaA * lambda_idt\n",
    "\n",
    "            # forward cycle loss\n",
    "            recon_A = G_B(fake_B)\n",
    "            cycle_A_loss = L1_loss(recon_A, real_A) * lambdaA * lambda_cycle\n",
    "\n",
    "            # B -> A\n",
    "            fake_A = G_B(real_B)\n",
    "            D_A_fake_decision = D_A(fake_A)\n",
    "    #         G_B_loss = D_loss_criterion(D_A_fake_decision,device,zeros=False,trick=False)\n",
    "            G_B_loss = D_loss_criterion(D_A_fake_decision) * lambdaB\n",
    "\n",
    "            # identity loss\n",
    "    #         G_B_idt_loss = L1_loss(fake_A, real_B) * lambdaB * lambda_idt\n",
    "\n",
    "            # backward cycle loss\n",
    "            recon_B = G_A(fake_A)\n",
    "            cycle_B_loss = L1_loss(recon_B, real_B) * lambdaB * lambda_cycle\n",
    "\n",
    "            # Back propagation\n",
    "            G_gan_loss = G_A_loss + G_B_loss\n",
    "            G_gan_losses.append(G_gan_loss)\n",
    "            G_cycle_loss = cycle_A_loss + cycle_B_loss\n",
    "            G_cycle_losses.append(G_cycle_loss)\n",
    "    #         G_idt_loss = G_A_idt_loss + G_B_idt_loss\n",
    "    #         G_idt_losses.append(G_idt_loss)\n",
    "\n",
    "    #         G_loss = G_gan_loss + G_cycle_loss + G_idt_loss\n",
    "            G_loss = -G_gan_loss + G_cycle_loss\n",
    "            G_optimizer.zero_grad()\n",
    "            G_loss.backward()\n",
    "            G_optimizer.step()\n",
    "        else:\n",
    "            #train D parameters\n",
    "            for model in [D_A, D_B]:\n",
    "                for param in model.parameters():\n",
    "                    param.requires_grad = True\n",
    "#                     param.data.clamp_(-0.01,0.01)\n",
    "\n",
    "            # Train discriminator D_A\n",
    "            D_A_optimizer.zero_grad()\n",
    "            \n",
    "            fake_A = G_B(real_B)\n",
    "            D_A_gradient_penalty = calc_gradient_penalty(D_A,real_A,fake_A)\n",
    "            \n",
    "            D_A_real_decision = D_A(real_A)     \n",
    "            D_A_real_loss = D_loss_criterion(D_A_real_decision)\n",
    "    #         D_A_real_loss = D_loss_criterion(D_A_real_decision,device,zeros=False,trick=True)\n",
    "            D_A_real_losses.append(D_A_real_loss)\n",
    "            \n",
    "            \n",
    "            fake_A = fake_A_pool.query(fake_A.detach())\n",
    "            D_A_fake_decision = D_A(fake_A)     \n",
    "            D_A_fake_loss = D_loss_criterion(D_A_fake_decision)\n",
    "    #         D_A_fake_loss = D_loss_criterion(D_A_fake_decision,device,zeros=True,trick=True)\n",
    "            D_A_fake_losses.append(D_A_fake_loss)\n",
    "            \n",
    "            # Back propagation\n",
    "            D_A_loss = D_A_fake_loss - D_A_real_loss + D_A_gradient_penalty\n",
    "    #         D_A_loss = (D_A_real_loss + D_A_fake_loss) * 0.5\n",
    "            D_A_loss.backward()\n",
    "            D_A_optimizer.step()\n",
    "\n",
    "            # Train discriminator D_B\n",
    "            D_B_optimizer.zero_grad()\n",
    "            \n",
    "            fake_B = G_A(real_A)\n",
    "            D_B_gradient_penalty = calc_gradient_penalty(D_B,real_B,fake_B)\n",
    "            \n",
    "            D_B_real_decision = D_B(real_B)\n",
    "            D_B_real_loss = D_loss_criterion(D_B_real_decision)\n",
    "    #         D_B_real_loss = D_loss_criterion(D_B_real_decision,device,zeros=False,trick=True)\n",
    "            D_B_real_losses.append(D_B_real_loss)          \n",
    "            \n",
    "            fake_B = fake_B_pool.query(fake_B.detach())\n",
    "            D_B_fake_decision = D_B(fake_B)\n",
    "            D_B_fake_loss = D_loss_criterion(D_B_fake_decision)\n",
    "    #         D_B_fake_loss = D_loss_criterion(D_B_fake_decision,device,zeros=True,trick=True)\n",
    "            D_B_fake_losses.append(D_B_fake_loss)         \n",
    "            \n",
    "            # Back propagation\n",
    "            D_B_loss = D_B_fake_loss - D_B_real_loss + D_B_gradient_penalty\n",
    "    #         D_B_loss = (D_B_real_loss + D_B_fake_loss) * 0.5\n",
    "            D_B_loss.backward()\n",
    "            D_B_optimizer.step()\n",
    "     \n",
    "    train_params = []\n",
    "    per_epoch_time = time.time() - epoch_start_time\n",
    "    train_params.append(per_epoch_time)\n",
    "    for loss in [G_gan_losses,G_cycle_losses,D_A_fake_losses,D_A_real_losses,D_B_fake_losses,D_B_real_losses]:\n",
    "        train_params.append(torch.mean(torch.FloatTensor(loss)))\n",
    "    \n",
    "    train_hist.add_params(train_params)\n",
    "    print(str.format('{}/{} ',starting_epoch+epoch+1,starting_epoch+train_epoch) + train_hist.get_last_param_str())\n",
    "    \n",
    "    #Save image result\n",
    "    with torch.no_grad():\n",
    "        G_A.eval()\n",
    "        G_B.eval()\n",
    "        for n, (x, _) in enumerate(train_loader_A):\n",
    "            x = x.to(device)\n",
    "            G_A_result = G_A(x)\n",
    "            G_A_recon = G_B(G_A_result)\n",
    "            result = torch.cat((x[0], G_A_result[0], G_A_recon[0]), 2)\n",
    "            path = os.path.join(project_result_path, 'Cycle_G_A', str(epoch+starting_epoch) + '_epoch_'  + '_train_' + str(n + 1) + '.png')\n",
    "            plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
    "            if n == 4:\n",
    "                break\n",
    "\n",
    "        for n, (x,_) in enumerate(train_loader_B):\n",
    "            x = x.to(device)\n",
    "            G_B_result = G_B(x)\n",
    "            G_B_recon = G_A(G_B_result)\n",
    "            result = torch.cat((x[0],G_B_result[0],G_B_recon[0]),2)\n",
    "            path = os.path.join(project_result_path,'Cycle_G_B',str(epoch+starting_epoch) + '_epoch_' +'_train_'+str(n+1)+'.png')\n",
    "            plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
    "            if n == 4:\n",
    "                break\n",
    "                \n",
    "        torch.save(G_A.state_dict(), os.path.join(project_result_path, 'G_A.pkl'))\n",
    "        torch.save(G_B.state_dict(), os.path.join(project_result_path, 'G_B.pkl')) \n",
    "        torch.save(D_A.state_dict(), os.path.join(project_result_path, 'D_A.pkl'))\n",
    "        torch.save(D_B.state_dict(), os.path.join(project_result_path, 'D_B.pkl'))\n",
    "        train_hist.save_train(os.path.join(project_result_path,  'train_hist.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
