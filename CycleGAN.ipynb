{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from lib import utils, networks, train_history\n",
    "import itertools\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input channel for generator\n",
    "in_ngc=3\n",
    "#output channel for generator\n",
    "out_ngc=3\n",
    "#input channel for discriminator\n",
    "in_ndc=3\n",
    "#output channel for discriminator\n",
    "out_ndc=1\n",
    "batch_size=10\n",
    "ngf=16\n",
    "ndf=32\n",
    "#the number of resnet block layer for generator\n",
    "nb=2\n",
    "#input size\n",
    "input_size=128\n",
    "ng_downsampling=5\n",
    "nd_downsampling=3\n",
    "\n",
    "train_epoch=20\n",
    "#Discriminator learning rate, default=0.0002\n",
    "lrD=0.0002\n",
    "#Generator learning rate, default=0.0002\n",
    "lrG=0.0002\n",
    "#lambda for loss\n",
    "lambdaA=1\n",
    "lambdaB=1\n",
    "lambda_cycle = 1\n",
    "# lambda_idt = 1\n",
    "decay_epoch = 10\n",
    "\n",
    "# wgan number of critics\n",
    "n_critic = 5\n",
    "\n",
    "#beta1 for Adam optimizer\n",
    "# beta1=0\n",
    "beta1 = 0.5\n",
    "#beta2 for Adam optimizer\n",
    "# beta2=0.9\n",
    "# beta2=0.999\n",
    "beta2=0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results path\n",
    "project_result_path='cycleGAN_9'\n",
    "cycle_A_path = os.path.join(project_result_path, 'Cycle_G_A')\n",
    "cycle_B_path = os.path.join(project_result_path, 'Cycle_G_B')\n",
    "if not os.path.isdir(cycle_A_path):\n",
    "    os.makedirs(cycle_A_path)\n",
    "if not os.path.isdir(cycle_B_path):\n",
    "    os.makedirs(cycle_B_path)\n",
    "\n",
    "#data path\n",
    "data_path = 'data'\n",
    "src_data_path= os.path.join(data_path,'src_data_path_new')\n",
    "tgt_data_path= os.path.join(data_path,'tgt_data_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.cudnn.enabled:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(0.1,0.1,0.1,0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_loader_A = torch.utils.data.DataLoader(datasets.ImageFolder(src_data_path, transform), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "train_loader_B = torch.utils.data.DataLoader(datasets.ImageFolder(tgt_data_path, transform), batch_size=batch_size, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n",
    "G_A = networks.cyclegan_generator1(in_ngc, out_ngc, ngf, nb, ng_downsampling)\n",
    "G_B = networks.cyclegan_generator1(in_ngc, out_ngc, ngf, nb, ng_downsampling)\n",
    "# D_A = networks.wgan_discriminator(in_ndc, ndf, input_size, nd_downsampling)\n",
    "# D_B = networks.wgan_discriminator(in_ndc, ndf, input_size, nd_downsampling)\n",
    "D_A = networks.discriminator(in_ndc, out_ndc, ndf)\n",
    "D_B = networks.discriminator(in_ndc, out_ndc, ndf)\n",
    "\n",
    "\n",
    "G_A.to(device)\n",
    "G_B.to(device)\n",
    "D_A.to(device)\n",
    "D_B.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "GAN_loss = nn.BCELoss().to(device)\n",
    "# GAN_loss = nn.MSELoss().to(device)\n",
    "L1_loss = nn.L1Loss().to(device)\n",
    "\n",
    "def D_loss_criterion(D_decision,device,zeros,trick=True):\n",
    "    if(zeros):\n",
    "        if(trick):\n",
    "            return GAN_loss(D_decision, torch.rand(D_decision.size(), device=device)/10.0)\n",
    "        return GAN_loss(D_decision, torch.zeros(D_decision.size(), device=device))\n",
    "    else:\n",
    "        if(trick):\n",
    "            return GAN_loss(D_decision, 1-torch.rand(D_decision.size(), device=device)/10.0)\n",
    "        return GAN_loss(D_decision, torch.ones(D_decision.size(), device=device))\n",
    "\n",
    "# def D_loss_criterion(D_decision):\n",
    "#     return D_decision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optimizer = optim.Adam(itertools.chain(G_A.parameters(), G_B.parameters()), lr=lrG, betas=(beta1, beta2))\n",
    "D_A_optimizer = optim.Adam(D_A.parameters(), lr=lrD, betas=(beta1, beta2))\n",
    "D_B_optimizer = optim.Adam(D_B.parameters(), lr=lrD, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = train_history.train_history(['per_epoch_time',\n",
    "                                          'G_gan_loss',\n",
    "                                          'G_cycle_loss',\n",
    "                                          'D_A_fake_loss',\n",
    "                                          'D_A_real_loss',\n",
    "                                          'D_B_fake_loss',\n",
    "                                          'D_B_real_loss'                                          \n",
    "                                          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_A.load_state_dict(torch.load(os.path.join(project_result_path, 'G_A.pkl')))\n",
    "G_B.load_state_dict(torch.load(os.path.join(project_result_path, 'G_B.pkl')))\n",
    "D_A.load_state_dict(torch.load(os.path.join(project_result_path, 'D_A.pkl')))\n",
    "D_B.load_state_dict(torch.load(os.path.join(project_result_path, 'D_B.pkl')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist.load_train(os.path.join(project_result_path, 'train_hist.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the starting_epoch if needed\n",
    "starting_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WGAN_calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    alpha = torch.rand(batch_size, 1)\n",
    "    alpha = alpha.expand(batch_size, real_data.nelement()//batch_size).contiguous()\n",
    "    alpha = alpha.view(batch_size, 3, input_size, input_size)\n",
    "    alpha = alpha.to(device)\n",
    "#     alpha = torch.rand(real_data.size(), device=device)\n",
    "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
    "    interpolates = interpolates.to(device)\n",
    "    interpolates.requires_grad_(True)   \n",
    "\n",
    "    disc_interpolates = netD(interpolates)\n",
    "    gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1) \n",
    "    gradient_penalty = 10* ((1-(gradients+1e-16).norm(2, dim=1)) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "def DRAGAN_calc_gradient_penalty(netD, X):\n",
    "    alpha = torch.rand(batch_size, 1)\n",
    "    alpha = alpha.expand(batch_size, X.nelement()//batch_size).contiguous()\n",
    "    alpha = alpha.view(batch_size, 3, input_size, input_size)\n",
    "    alpha = alpha.to(device)\n",
    "    x_hat = alpha * X.data + (1 - alpha) * (X.data + 0.5 * X.data.std() * torch.rand(X.size(),device=device))\n",
    "    x_hat.to(device)\n",
    "    x_hat.requires_grad_(True)\n",
    "    pred_hat = netD(x_hat)\n",
    "    gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()).to(device),\n",
    "            create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    gradients_penalty = 10 * ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    gradients_penalty.backward(retain_graph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start!\n",
      "==> Epoch 1/20\n",
      "1/20 per_epoch_time:289.920,G_gan_loss:2.471,G_cycle_loss:0.950,D_A_fake_loss:0.492,D_A_real_loss:0.510,D_B_fake_loss:0.586,D_B_real_loss:0.584,\n",
      "==> Epoch 2/20\n",
      "2/20 per_epoch_time:291.572,G_gan_loss:2.725,G_cycle_loss:0.912,D_A_fake_loss:0.454,D_A_real_loss:0.486,D_B_fake_loss:0.547,D_B_real_loss:0.561,\n",
      "==> Epoch 3/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6eeba7715349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mD_B_fake_decision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mG_A_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_loss_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_B_fake_decision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrick\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlambdaA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;31m#         G_A_loss = D_loss_criterion(D_B_fake_decision)  * lambdaA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6c1de36c1f9d>\u001b[0m in \u001b[0;36mD_loss_criterion\u001b[0;34m(D_decision, device, zeros, trick)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrick\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mGAN_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_decision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_decision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mGAN_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_decision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_decision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# def D_loss_criterion(D_decision):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print('training start!')\n",
    "start_time = time.time()\n",
    "num_pool = 50\n",
    "fake_A_pool = utils.ImagePool(num_pool)\n",
    "fake_B_pool = utils.ImagePool(num_pool)\n",
    "for epoch in range(train_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    print(\"==> Epoch {}/{}\".format(starting_epoch+epoch + 1, starting_epoch+train_epoch))\n",
    "    if (epoch + 1) > decay_epoch:\n",
    "        D_A_optimizer.param_groups[0]['lr'] -= lrD / 10\n",
    "        D_B_optimizer.param_groups[0]['lr'] -= lrD / 10\n",
    "        G_optimizer.param_groups[0]['lr'] -= lrG / 10\n",
    "    \n",
    "    G_gan_losses = []\n",
    "    G_cycle_losses = []\n",
    "\n",
    "    D_A_real_losses = []\n",
    "    D_A_fake_losses = []\n",
    "    D_B_real_losses = []\n",
    "    D_B_fake_losses = []\n",
    "\n",
    "    for (real_A,_),(real_B,_) in zip(train_loader_A, train_loader_B):\n",
    "        G_A.train()\n",
    "        G_B.train()\n",
    "\n",
    "        # input image data\n",
    "        real_A = real_A.to(device)\n",
    "        real_B = real_B.to(device)\n",
    "#         if(i%5 == 0):\n",
    "        #fix D parameters\n",
    "        for model in [D_A, D_B]:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Train generator G\n",
    "        # A -> B\n",
    "        fake_B = G_A(real_A)\n",
    "        D_B_fake_decision = D_B(fake_B)\n",
    "        G_A_loss = D_loss_criterion(D_B_fake_decision,device,zeros=False,trick=False) * lambdaA\n",
    "#         G_A_loss = D_loss_criterion(D_B_fake_decision)  * lambdaA\n",
    "\n",
    "        # identity loss\n",
    "#         G_A_idt_loss = L1_loss(fake_B, real_A) * lambdaA * lambda_idt\n",
    "\n",
    "        # forward cycle loss\n",
    "        recon_A = G_B(fake_B)\n",
    "        cycle_A_loss = L1_loss(recon_A, real_A) * lambdaA * lambda_cycle\n",
    "\n",
    "        # B -> A\n",
    "        fake_A = G_B(real_B)\n",
    "        D_A_fake_decision = D_A(fake_A)\n",
    "        G_B_loss = D_loss_criterion(D_A_fake_decision,device,zeros=False,trick=False) * lambdaB\n",
    "#         G_B_loss = D_loss_criterion(D_A_fake_decision) * lambdaB\n",
    "\n",
    "        # identity loss\n",
    "#         G_B_idt_loss = L1_loss(fake_A, real_B) * lambdaB * lambda_idt\n",
    "\n",
    "        # backward cycle loss\n",
    "        recon_B = G_A(fake_A)\n",
    "        cycle_B_loss = L1_loss(recon_B, real_B) * lambdaB * lambda_cycle\n",
    "\n",
    "        # Back propagation\n",
    "        G_gan_loss = G_A_loss + G_B_loss\n",
    "        G_gan_losses.append(G_gan_loss)\n",
    "        G_cycle_loss = cycle_A_loss + cycle_B_loss\n",
    "        G_cycle_losses.append(G_cycle_loss)\n",
    "#         G_idt_loss = G_A_idt_loss + G_B_idt_loss\n",
    "#         G_idt_losses.append(G_idt_loss)\n",
    "\n",
    "#         G_loss = G_gan_loss + G_cycle_loss + G_idt_loss\n",
    "#         G_loss = -G_gan_loss + G_cycle_loss\n",
    "        G_loss = G_gan_loss + G_cycle_loss\n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "#         else:\n",
    "        #train D parameters\n",
    "        for model in [D_A, D_B]:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = True\n",
    "#                     param.data.clamp_(-0.01,0.01)\n",
    "\n",
    "        # Train discriminator D_A\n",
    "        D_A_optimizer.zero_grad()\n",
    "\n",
    "        fake_A = G_B(real_B)\n",
    "#         D_A_gradient_penalty = WGAN_calc_gradient_penalty(D_A,real_A,fake_A)\n",
    "#         D_A_gradient_penalty = DRAGAN_calc_gradient_penalty(D_A,real_A)\n",
    "#         DRAGAN_calc_gradient_penalty(D_A,real_A)\n",
    "        \n",
    "        D_A_real_decision = D_A(real_A)     \n",
    "#         D_A_real_loss = D_loss_criterion(D_A_real_decision)\n",
    "        D_A_real_loss = D_loss_criterion(D_A_real_decision,device,zeros=False,trick=True)\n",
    "        D_A_real_losses.append(D_A_real_loss)\n",
    "\n",
    "\n",
    "        fake_A = fake_A_pool.query(fake_A.detach())\n",
    "        D_A_fake_decision = D_A(fake_A)     \n",
    "#         D_A_fake_loss = D_loss_criterion(D_A_fake_decision)\n",
    "        D_A_fake_loss = D_loss_criterion(D_A_fake_decision,device,zeros=True,trick=True)\n",
    "        D_A_fake_losses.append(D_A_fake_loss)\n",
    "\n",
    "        # Back propagation\n",
    "#         D_A_loss = D_A_fake_loss - D_A_real_loss + D_A_gradient_penalty\n",
    "        D_A_loss = D_A_fake_loss + D_A_real_loss\n",
    "#         D_A_loss = (D_A_real_loss + D_A_fake_loss) * 0.5\n",
    "        D_A_loss.backward()\n",
    "        D_A_optimizer.step()\n",
    "\n",
    "        # Train discriminator D_B\n",
    "        D_B_optimizer.zero_grad()\n",
    "\n",
    "        fake_B = G_A(real_A)\n",
    "#         D_B_gradient_penalty = WGAN_calc_gradient_penalty(D_B,real_B,fake_B)\n",
    "#         DRAGAN_calc_gradient_penalty(D_B,real_B)\n",
    "\n",
    "        D_B_real_decision = D_B(real_B)\n",
    "#         D_B_real_loss = D_loss_criterion(D_B_real_decision)\n",
    "        D_B_real_loss = D_loss_criterion(D_B_real_decision,device,zeros=False,trick=True)\n",
    "        D_B_real_losses.append(D_B_real_loss)          \n",
    "\n",
    "        fake_B = fake_B_pool.query(fake_B.detach())\n",
    "        D_B_fake_decision = D_B(fake_B)\n",
    "#         D_B_fake_loss = D_loss_criterion(D_B_fake_decision)\n",
    "        D_B_fake_loss = D_loss_criterion(D_B_fake_decision,device,zeros=True,trick=True)\n",
    "        D_B_fake_losses.append(D_B_fake_loss)         \n",
    "\n",
    "        # Back propagation\n",
    "#         D_B_loss = D_B_fake_loss - D_B_real_loss + D_B_gradient_penalty\n",
    "        D_B_loss = D_B_fake_loss + D_B_real_loss\n",
    "#         D_B_loss = (D_B_real_loss + D_B_fake_loss) * 0.5\n",
    "        D_B_loss.backward()\n",
    "        D_B_optimizer.step()\n",
    "     \n",
    "    train_params = []\n",
    "    per_epoch_time = time.time() - epoch_start_time\n",
    "    train_params.append(per_epoch_time)\n",
    "    for loss in [G_gan_losses,G_cycle_losses,D_A_fake_losses,D_A_real_losses,D_B_fake_losses,D_B_real_losses]:\n",
    "        train_params.append(torch.mean(torch.FloatTensor(loss)))\n",
    "    \n",
    "    train_hist.add_params(train_params)\n",
    "    print(str.format('{}/{} ',starting_epoch+epoch+1,starting_epoch+train_epoch) + train_hist.get_last_param_str())\n",
    "    \n",
    "    #Save image result\n",
    "    with torch.no_grad():\n",
    "        G_A.eval()\n",
    "        G_B.eval()\n",
    "        for n, (x, _) in enumerate(train_loader_A):\n",
    "            x = x.to(device)\n",
    "            G_A_result = G_A(x)\n",
    "            G_A_recon = G_B(G_A_result)\n",
    "            result = torch.cat((x[0], G_A_result[0], G_A_recon[0]), 2)\n",
    "            path = os.path.join(project_result_path, 'Cycle_G_A', str(epoch+starting_epoch) + '_epoch_'  + '_train_' + str(n + 1) + '.png')\n",
    "            plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
    "            if n == 4:\n",
    "                break\n",
    "\n",
    "        for n, (x,_) in enumerate(train_loader_B):\n",
    "            x = x.to(device)\n",
    "            G_B_result = G_B(x)\n",
    "            G_B_recon = G_A(G_B_result)\n",
    "            result = torch.cat((x[0],G_B_result[0],G_B_recon[0]),2)\n",
    "            path = os.path.join(project_result_path,'Cycle_G_B',str(epoch+starting_epoch) + '_epoch_' +'_train_'+str(n+1)+'.png')\n",
    "            plt.imsave(path, (result.cpu().numpy().transpose(1, 2, 0) + 1) / 2)\n",
    "            if n == 4:\n",
    "                break\n",
    "                \n",
    "        torch.save(G_A.state_dict(), os.path.join(project_result_path, 'G_A.pkl'))\n",
    "        torch.save(G_B.state_dict(), os.path.join(project_result_path, 'G_B.pkl')) \n",
    "        torch.save(D_A.state_dict(), os.path.join(project_result_path, 'D_A.pkl'))\n",
    "        torch.save(D_B.state_dict(), os.path.join(project_result_path, 'D_B.pkl'))\n",
    "        train_hist.save_train(os.path.join(project_result_path,  'train_hist.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
